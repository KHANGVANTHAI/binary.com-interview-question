---
title: "<img src='www/binary-logo-resize.jpg' width='240'>"
subtitle: "[binary.com](https://github.com/englianhu/binary.com-interview-question) Interview Question I - Multivariate GARCH Models"
author: "[®γσ, Lian Hu](https://englianhu.github.io/) <img src='www/RYO.jpg' width='24'> <img src='www/RYU.jpg' width='24'> <img src='www/ENG.jpg' width='24'>®"
date: "`r lubridate::today('Asia/Tokyo')`"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup}
suppressPackageStartupMessages(library('BBmisc'))
#'@ suppressPackageStartupMessages(library('rmsfuns'))

pkgs <- c('knitr', 'kableExtra', 'devtools', 'lubridate', 'data.table', 'quantmod', 'qrmtools', 'tidyquant', 'plyr', 'stringr', 'magrittr', 'dplyr', 'tidyverse', 'memoise', 'highcharter', 'formattable', 'DT', 'rugarch', 'ccgarch', 'mgarchBEKK', 'rmgarch')

suppressAll(lib(pkgs))
#'@ load_pkg(pkgs)

funs <- c('calc_fx.R', 'opt_arma.R', 'filterFX.R', 'filter_spec.R', 'mv_fx.R', 'read_umodels.R')
l_ply(funs, function(x) source(paste0('./function/', x)))

options(warn = -1)
rm(pkgs)
```

# Introduction

## VaR

From previous papers, I tried to apply few models for FOREX price forecasting and eventually got to know <span style='color:red'>Fractional Intergrated GJR-GARCH</span> is the best fit model as we can refer to *GARCH模型中的ARIMA(p,d,q)参数最优化*. **The standalone ARFIMAX model and methods** in the [A short introduction to the rugarch package](http://www.unstarched.net/r-examples/rugarch/a-short-introduction-to-the-rugarch-package/) describe the `autoarfima()` function where we can easily get the optimal MA and AR figure.

Today I am zooming into the multivariate GARCH models. Start from this paper, I will stored the forecast VaR value as well, kindly refer to *How Good Are Your VaR Estimates?*^ for more information. 

- *ARMA(1,1)-GARCH(1,1)
Estimation and forecast using rugarch 1.2-2*
- [An Introduction to Value at Risk (VAR)](https://www.investopedia.com/articles/04/092904.asp)
- [Multivariate GARCH with respect to Value at Risk](https://stats.stackexchange.com/questions/130227/multivariate-garch-with-respect-to-value-at-risk?answertab=votes#tab-top) is the another article about VaR in multivariate models.
- [Difference between uGarchRoll Value at Risk and manual calculations](https://stats.stackexchange.com/questions/298381/difference-between-ugarchroll-value-at-risk-and-manual-calculations?answertab=votes#tab-top)
- [ARMA(1,1)-GARCH(1,1)
Estimation and forecast using rugarch 1.2-2](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/ARMA(1%2C1)-GARCH(1%2C1)%20Estimation%20and%20Forecast%20using%20rugarch%201.2-2.pdf)
- [Issues in estimating VaR with GARCH](https://quant.stackexchange.com/questions/25946/issues-in-estimating-var-with-garch?answertab=votes#tab-top)
- [Value-At-Risk (VaR) curve with Copula-GARCH model (R)](https://stackoverflow.com/questions/40174020/value-at-risk-var-curve-with-copula-garch-model-r)
- [Calculation of VaR of a time series using a GARCH(1,1) ARMA(1,1) model](https://stats.stackexchange.com/questions/136958/calculation-of-var-of-a-time-series-using-a-garch1-1-arma1-1-model?answertab=votes#tab-top)
- [Fitting and Predicting VaR based on an ARMA-GARCH Process](https://cran.r-project.org/web/packages/qrmtools/vignettes/ARMA_GARCH_VaR.html)

```
# conditional mean 
cmu = as.numeric(as.data.frame(forecast, which = "series", 
rollframe="all", aligned = FALSE)) 
# conditional sigma 
csigma = as.numeric(as.data.frame(forecast, which = "sigma", 
rollframe="all", aligned = FALSE)) 

I can calculate the VaR by using the property, that the normal distribution 
is part of the location-scale distribution families 

# use location+scaling transformation property of normal distribution: 
VaR = qnorm(0.01)*csigma + cmu
```

*source : [rugarch VaR calculation "manually"](http://r.789695.n4.nabble.com/rugarch-VaR-calculation-quot-manually-quot-td4666462.html)*

> For your purpose, you need a random variable with zero mean and unit variance. However, the variance of the Student-t distribution is νν−2 for ν>2 and not one, where ν are the degrees of freedom.
> 
> You get the correct VaR by multiplying the quantile of the Student-t distribution with ν−2ν−−−√:
> 
> 0.1262 + 1.059 * qt(0.05, 4.68) * sqrt((4.68-2) / 4.68)
[1] -1.51334
Alternatively, using the rugarch package which defaults to standardized distributions:
> 
> rugarch::qdist("std", 0.05, mu=0.1262, sigma=1.059, shape=4.68)
[1] -1.51334

*source : [Difference between uGarchRoll Value at Risk and manual calculations](https://stats.stackexchange.com/questions/298381/difference-between-ugarchroll-value-at-risk-and-manual-calculations?answertab=votes#tab-top)*

## VaR for Long and Short

- [Value-at-Risk for long and short trading positions - Evidence from developed and emerging equity markets]()
- [Value-at-Risk for Long and Short Trading Positions]()
- [Value at Risk for Long-Short Positions]()

# Data

## Read Data

Similar with *GARCH模型中的ARIMA(p,d,q)参数最优化*, I use the dataset from [Binary-Q1 (Extention)](http://rpubs.com/englianhu/binary-Q1E).

```{r read-data, warning=FALSE}
cr_code <- c('AUDUSD=X', 'EURUSD=X', 'GBPUSD=X', 'CHF=X', 'CAD=X', 
             'CNY=X', 'JPY=X')

#'@ names(cr_code) <- c('AUDUSD', 'EURUSD', 'GBPUSD', 'USDCHF', 'USDCAD', 
#'@                     'USDCNY', 'USDJPY')

names(cr_code) <- c('USDAUD', 'USDEUR', 'USDGBP', 'USDCHF', 'USDCAD', 'USDCNY', 'USDJPY')

## Read presaved Yahoo data.
mbase <- sapply(names(cr_code), function(x) readRDS(paste0('./data/', x, '.rds')) %>% na.omit)
```

# Modelling

## Introduce Multivariate Garch Models

Multivariate GARCH models including DCC, GO-GARCH and Copula-GARCH, CCC and BEKK. Paper *Comparison of Multivariate GARCH Models with Application to Zero-Coupon Bond Volatility* compares DCC and BEKK model on bond market with maturities of 6 months, 1 year and 2 years. The thesis concludes that the fitting performance of the BEKK is better than DCC in their case, the difference might due to the number of the parameters of BEKK model is comparatively more, so that the BEKK has a better capanility in explaning the information hidden in the hostory data. In opposite, the DCC model has an advantage over the BEKK model in the area of forecasting as the DCC model is more parsimonious than BEKK model. From my understanding means that if we compare with deviance or AIC/BIC the DCC will be more accurate. However, this paper will compare as well since forex market is not bond market.

*Currency Hedging Strategies Using Dynamic Multivariate GARCH* compares DCC, BEKK, CCC and VARMA-AGARCH models to examine the conditional volatilities among the spot and two distint futures maturities, namely near-month and next-to-near-month contracts. The estimated conditionl covariances matrices from these models were used to calculate the optimal portfolios weights and optimal hedge ratios.^[Kindly refer to ] The empirical results in the paper reveal that there are not big differences either the near-month or next-to-near-month contract is used for hedge spot position on currencies. They also reveal that hedging ratios are lower for near-month contract when the USD/EUR and USD/JPY exchange rates are anlyzed. This result is explained in terms of the higher correlation between spot prices and the next-to-near-month future prices than that with near-month contract and additionally because of the lower volatility of the long maturity futures. Finally across all currencies and error densities, the CCC and VARMA-AGARCH models provide similar results in terms of hedging ratios, portfolio variance reduction and hedging effectiveness. Some difference might appear when the DCC and BEKK models are used. Below is the table summary of the paper.

```{r, echo=FALSE}
dfm1 <- data_frame(
  Model = c('CCC'), 
  Currency = c('EURS', 'GBPS', 'JPYS'), 
  AIC = c(2.738605, 2.247209, 2.827915))

dfm2 <- data_frame(
  Model = c('VARMA-AGARCH'), 
  Currency = c('EURS', 'GBPS', 'JPYS'), 
  AIC = c(2.734926, 2.241061, 2.828964))

dfm3 <- data_frame(
  Model = c('DCC'), 
  Currency = c('EURS', 'GBPS', 'JPYS'), 
  AIC = c(2.721337, 2.205663, 2.784974))

dfm4 <- data_frame(
  Model = c('BEKK'), 
  Currency = c('EURS', 'GBPS', 'JPYS'), 
  AIC = c(2.735964, 2.212324, 2.788730))

dfm <- list(dfm1, dfm2, dfm3, dfm4) %>% 
  bind_rows %>% 
  mutate_if(is.character, as.factor) %>% 
  arrange(Currency)

rm(dfm1, dfm2, dfm3, dfm4)
dfm %>% 
  kable(caption = 'Comparison Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  group_rows('EURS', 1, 4, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('GBPS', 5, 8, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  group_rows('JPYS', 9, 12, label_row_css = 'background-color: #003399; color: #fff;') %>%

  scroll_box(width = '100%', height = '400px')
```

*Table 3.1.1 : comparison of the models.*

Table above shows DCC model is the best fit model.

*Do We Really Need Both BEKK and DCC - A Tale of Two Multivariate GARCH Models* compares few models and final model should be based on model performance within the appropriate framework in which they are used (such as covariance, correlation forecasting, risk monitoringm or portfolio allocation, to cite the most relevant), the paper concludes that the cDCC (constant DCC) model^[Similar with paper *Aielli (2010)* who suggest using cDCC model insted of the DCC model of *Engle (2002)*. Similar with papers *Engle et al. (2008)* and *Engle Engle and Kelly (2009)*.] and BEKK model.

*Forecasting the Daily Dynamic Hedge Ratios by GARCH Models - Evidence from the Agricultural Futures Markets* compares few models which are bivariate GARCH, BEKK GARCH, GARCH-X, BEKK-X, Q-GARCH and GARCH-GJR in agricultural futures markets. The paper reveals that the BEKK model dominates others models for storable wheat and soybean for both forecasting horizons, and the asymmetric GJR andQ-GARCH models does the best forecasting performance for the non-storable products, live cattle and live hogs.

*Dynamic Portfolio Optimization using Generalized Dynamic Conditional Heteroskedastic Factor Models* compares . The paper studies the portfolio selection problem based on a generalized dynamic factor model (GDFM) with conditional heteroskedasticity in the idiosyncratic components. We propose a Generalized Smooth Transition Conditional Correlation (GSTCC) model for the idiosyncratic components combined with the GDFM. Among all the multivariate GARCH models that the authors propose, the generalized smooth transition conditional correlation provides the best result.

![](www/ROI-DPO-03.jpg)

![](www/ROI-DPO-04.jpg)

I try to surf over internet and the model has no yet widely use. Here I can only use the CCC, DCC models but the best performance GSTCC is not yet available in r packages. The `cccgarch` has STCC model but there has no examples to use it. I roughly read over the `ccgarch` package and noticed that all parameters required in matrix format which is only suitable for advance user use.

*Forecasting Conditional Correlation for Exchange Rates using Multivariate GARCH Models with Historical Value-at-Risk Application* compares the VaR for trade in USDSEK in T+1 and T+10 with intraday 30 minutes time interval. When comparing the BEKK and DCC model, the BEKK seems to perform better than the DCC in both forecasting conditional correlation and predicting VaR. On the contrary, the BEKK is much more computationally demanding, which most certainly would be even more noticeable when the number of assets increase.

![](www/USDSEK-VaR01.jpg)

![](www/USDSEK-VaR02.jpg)

## Parameter Selection

```{r dcc1, echo=FALSE, eval=FALSE}
### ========= using cluster for sampling ===============
fit <- llply(na.omit(Cl(mbase[['USDJPY']])), function(x){
  
  armaOrder = opt_arma(x)
  
  xspec = ugarchspec(
    variance.model = list(
      model = 'gjrGARCH', garchOrder = c(1, 1), 
      submodel = NULL, external.regressors = NULL, 
      variance.targeting = FALSE), 
    mean.model = list(
      armaOrder = armaOrder[c(1, 3)], 
      include.mean = TRUE, archm = FALSE, 
      archpow = 1, arfima = TRUE, 
      external.regressors = NULL, 
      archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
  uspec = multispec(replicate(4, xspec))
  
  spec1 = dccspec(uspec = uspec, dccOrder = c(1, 1), 
                  model='aDCC', distribution = 'mvt')
  
  cl = makePSOCKcluster(4)
  multf = multifit(uspec, x, cluster = cl)
  
  fit1 = dccfit(spec1, data = x, solver = 'hybrid', 
                fit.control = list(eval.se = TRUE), 
                fit = multf, cluster = cl)
  
  return(fit1)
  })
```

My initially workable models result.

```{r wdcc-aic}
workable.dcc <- readRDS('data/fx/pt.dcc.rds')

#'@ dcc.AIC <- ldply(workable.dcc, function(x) {
#'@     ldply(x, function(y) {
#'@             list.select(y, AIC) %>% 
#'@             data.frame %>% t %>% data.frame %>% 
#'@             mutate(includes.Op = c(TRUE, FALSE))
#'@     }) %>% rename(.solver = .id)
#'@   }) %>% 
#'@   dplyr::select(.id, .solver, includes.Op, Akaike, Bayes, Shibata, Hannan.Quinn)

dcc.AIC <- ldply(workable.dcc, function(x) {
    zz <- ldply(x, function(y) {
        zz <- ldply(y, function(z) {
            z$AIC %>% 
            data.frame %>% t %>% data.frame
        })
        names(zz)[1] <- 'includes.Op'
        zz
    })
    names(zz)[1] <- '.solver'
    zz
  })

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.1.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model.

```{r dcc-llh}
dcc.logLik <- ldply(workable.dcc, function(x) {
    zz = ldply(x, function(y) {
        zz = ldply(y, function(z) {
            attributes(z$fit)$mfit$llh
        })
        names(zz) <- c('includes.Op', 'log.Likelihood')
        zz
    })
    names(zz)[1] <- '.solver'
    zz
  })

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.1.2 : Log-Likelihood comparison.*

### Close Price

```{r bk-dcc, eval=FALSE}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')

## Includes the open price or not.
bk.base <- llply(mbase, Cl)
bk.base %<>% do.call(cbind, .) %>% na.omit

## Statistical modelling
bk.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    fit <- tryCatch(
      mv_fx(bk.base, .model = x, .solver = y, 
            .include.Op = FALSE, .Cl.only = TRUE), 
      error = function(e) cat(paste0('bk.', x, '.', y, ' error.\n')))
  
  if (!is.null('fit')) {
    eval(parse(text = paste0(
      "saveRDS(fit, 'data/fx/", paste0('bk.', x, '.', y), ".rds')")))
    cat(paste0('bk.', x, '.', y, ' saved.\n'))
  }
  })
  names(dm) <- sv
  dm
})
names(bk.dcc) <- md
```

I executed above coding and there are quite some models occured errors. The `FDCC` models do faced error even though change all possible solvers. Below I read presaved data which executed above.

```{r read-bkdcc}
fls <- list.files('data/fx', pattern = '^bk.') %>% str_replace_all('.rds', '')

bk.dcc <- sapply(fls, function(x) readRDS(paste0('data/fx/', x, '.rds'))) %>% 
  filterNull
```

Here I tried to compare the AIC values. The lowest value will be best fit model.

```{r bkdcc-aic}
##compare AIC values.
dcc.AIC <- sapply(bk.dcc, function(x) data.frame(t(x$AIC))) %>% 
    t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver')) %>% 
    dplyr::select(.id, .model, .solver, Akaike, Bayes, Shibata, Hannan.Quinn)
rownames(dcc.AIC) <- NULL

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.3.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model.
After that, look at the log-likehood figure as well to compare the correlation among models. The highest value will be best fit model.

```{r bkdcc-logLik}
##compare AIC values.
dcc.logLik <- sapply(bk.dcc, function(x) attributes(x$fit)$mfit$llh) %>% 
    t %>% t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver'))
rownames(dcc.logLik) <- NULL
names(dcc.logLik)[1] <- 'log.Likelihood'
dcc.logLik %<>% dplyr::select(.id, .model, .solver, log.Likelihood)

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.3.2 : Log-Likelihood comparison.*

```{r bkdcc-roll}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')

## Includes the open price or not.
bk.base <- llply(mbase, Cl)
bk.base %<>% do.call(cbind, .) %>% na.omit

## Statistical modelling
bk.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    fit <- tryCatch(
      mv_fx(bk.base, .model = x, .solver = y, 
            .include.Op = FALSE, .Cl.only = TRUE, .roll = TRUE), 
      error = function(e) cat(paste0('roll.bk.', x, '.', y, ' error.\n')))
  
  if (!is.null('fit')) {
    eval(parse(text = paste0(
      "saveRDS(fit, 'data/fx/", paste0('roll.bk.', x, '.', y), ".rds')")))
    cat(paste0('roll.bk.', x, '.', y, ' saved.\n'))
  }
  })
  names(dm) <- sv
  dm
})
names(bk.dcc) <- md
```


### Hi-Lo Price

#### Single Currency

Multivariate modelling for single currency. Here I tried to seperate to 2 type of forecasting dataset which are `OHLC` and `HLC` to know if includes the open price will be more accurate or not.

```{r pt-dcc, eval=FALSE}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')
op <- c(TRUE, FALSE)

## Includes the open price or not.
pt.base <- mbase[['USDJPY']][,1:4]

## Statistical modelling
pt.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    TF <- llply(op, function(z) {
      fit <- tryCatch(
        mv_fx(pt.base, .model = x, .solver = y, 
              .include.Op = z, .Cl.only = FALSE), 
        error = function(e) 
          cat(paste0('pt.', x, '.', y, '.', z,' error.\n')))
      
      if (!is.null('fit')) {
        eval(parse(text = paste0(
          "saveRDS(fit, 'data/fx/", 
          paste0('pt.', x, '.', y, '.', z), ".rds')")))
        cat(paste0('pt.', x, '.', y, '.', z, ' saved.\n'))
        }
    })
    names(TF) <- op
    TF
  })
  names(dm) <- sv
  dm
})
names(pt.dcc) <- md
```

I executed above coding and there are quite some models occured errors. The `FDCC` models do faced error even though change all possible solvers. Below I read presaved data which executed above.

```{r read-ptdcc}
fls <- list.files('data/fx', pattern = '^pt.[^dcc]') %>% str_replace_all('.rds', '')

pt.dcc <- sapply(fls, function(x) readRDS(paste0('data/fx/', x, '.rds'))) %>% 
  filterNull
```

Here I tried to compare the AIC values. The lowest value will be best fit model.

```{r ptdcc-aic}
##compare AIC values.
dcc.AIC <- sapply(pt.dcc, function(x) data.frame(t(data.frame(x$AIC)))) %>% 
    t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver', 'includes.Op')) %>% 
    dplyr::select(.id, .model, .solver, includes.Op, Akaike, Bayes, Shibata, Hannan.Quinn)
rownames(dcc.AIC) <- NULL

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.4.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model. After that, look at the log-likehood figure as well to compare the correlation among models. The highest value will be best fit model.

```{r ptdcc-logLik}
##compare AIC values.
dcc.logLik <- sapply(pt.dcc, function(x) attributes(x$fit)$mfit$llh) %>% 
    t %>% t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver', 'includes.Op'))
rownames(dcc.logLik) <- NULL
names(dcc.logLik)[1] <- 'log.Likelihood'
dcc.logLik %<>% dplyr::select(.id, .model, .solver, includes.Op, log.Likelihood)

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.4.2 : Log-Likelihood comparison.*

The model `r dcc.logLik %>% dplyr::filter(log.Likelihood == max(log.Likelihood)) %>% unite(.id, .id:includes.Op) %>% .$.id %>% str_replace_all('_', '.')` which highest logLik value `r dcc.logLik$log.Likelihood[which.max(dcc.logLik$log.Likelihood)]` is the best fitted model for correlation.

```{r ptdcc-roll}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')
op <- c(TRUE, FALSE)

## Includes the open price or not.
pt.base <- mbase[['USDJPY']][,1:4]

## Statistical modelling
pt.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    TF <- llply(op, function(z) {
      fit <- tryCatch(
        mv_fx(pt.base, .model = x, .solver = y, 
              .include.Op = z, .Cl.only = FALSE, .roll = TRUE), 
        error = function(e) 
          cat(paste0('roll.pt.', x, '.', y, '.', z,' error.\n')))
      
      if (!is.null('fit')) {
        eval(parse(text = paste0(
          "saveRDS(fit, 'data/fx/", 
          paste0('roll.pt.', x, '.', y, '.', z), ".rds')")))
        cat(paste0('roll.pt.', x, '.', y, '.', z, ' saved.\n'))
        }
    })
    names(TF) <- op
    TF
  })
  names(dm) <- sv
  dm
})
names(pt.dcc) <- md
```

#### Currency Basket

Nested multivariate modelling for a basket of currencies will compares in following section.

### Concludes Parameter Selection

I initially wonder if I need to includes the open price in the models. Therefore I tried to compare above models. However the open price might not in use the my trading strategy. Therefore here I skip it. Here I seperates to 3 selection for trading:

- Hi-Lo
- Hi-Lo-Cl
- Cl

## DCC

### Abtract of DDC

Due to article *The GARCH DCC Model and 2 Stage DCCMVT Estimation*^[Kindly refer to [Reference] for further reading.] compares the `model = c('DCC', 'aDCC')` but not `model = 'FDCC'` with all distributions and concludes that `aDCC` with `distribution = 'mvt'` is the best fit model and distribution for multivariate GARCH model. Here I directly use `mvt` but in different `solver` parameters.

The paper [Binary.com Interview Q1 - Comparison of Univariate GARCH Models](https://rpubs.com/englianhu/binary-Q1Uni-GARCH) describes the GARCH orders. [How to identify the ARCH and GARCH lag length in dynamic conditional correlation GARCH model?](https://stats.stackexchange.com/questions/136302/how-to-identify-the-arch-and-garch-lag-length-in-dynamic-conditional-correlation?answertab=votes#tab-top) describes the GARCH(1,1) and also DCC-GARCH as well.

*Multivariate DCC-GARCH Model* introduce the DCC and CCC models. In all tests for marginal goodness of fit the DCC-GARCH with skew Student's t-distributed errors outperformed the DCC-GARCH with Gaussian and Student's t-distributed errors. Comparing the DCC-GARCH model with the CCC-GARCH model using the Kupiec test showed that the DCC-GARCH model gave a better fit to the data.

**VAR and Robust**

Below models will set `VAR=TRUE` <s>and `robust=FALSE`</s> and `VAR=FALSE` to test if it is more accurate.

> If you have a multivariate conditional mean specification (i.e. VAR) then you cannot have a univariate conditional mean specification (arma model)...they are mutually exclusive. In short, do not enter anything for mean.model in ugarchspec (include.mean is automatically set to FALSE if VAR is selected).

*source : [rmgarch:dccforecast() and mregfor](http://r.789695.n4.nabble.com/rmgarch-dccforecast-and-mregfor-td4675161.html) or [how to test significance of VAR coefficients in DCC GARCH Fit](http://r.789695.n4.nabble.com/how-to-test-significance-of-VAR-coefficients-in-DCC-GARCH-Fit-td4472274.html)*

> Currently the DCCfit object (returned from running dccfit) does not return all the information on the VAR (coefficients can be extracted by looking at the model slot and 'varcoef' list i.e. fit at model$varcoef).
> 
> A better approach is to first estimate the VAR model using the function 'varxfit' in the package which returns the standard errors and all relevant information, and then passing this returned object to the dccfit routine (example follows).

```
#################
library(rmgarch)
data(dji30ret)
Data = dji30ret[, 1:3, drop = FALSE]

vfit = varxfit(X=Data, p=1, exogen = NULL, robust = FALSE,
gamma = 0.25, delta = 0.01, nc = 10, ns = 500, postpad = "constant")

uspec = ugarchspec(mean.model = list(armaOrder = c(0,0), include.mean = 
FALSE), variance.model = list(garchOrder = c(1,1), model = "sGARCH"),
distribution.model = "norm")

spec = dccspec(uspec = multispec( replicate(3, uspec) ), VAR = TRUE,
lag = 1, dccOrder = c(1,1), asymmetric = FALSE, distribution = "mvnorm")

fit = dccfit(spec, data = Data, fit.control = list(eval.se=TRUE), 
VAR.fit = vfit)
#################
```

> The package also includes for convenience the 'varxfilter', 'varxforecast' and 'varxsim' functions which are used by the multivariate garch routines internally.
> 
> As mentioned in the documentation, a comprehensive list of examples are included in the 'inst/rmgarch.tests' folder of the package.
> 
> Regards,
> 
> Alexios

*source : [[R-SIG-Finance] how to test significance of VAR coefficients in DCC GARCH Fit](https://stat.ethz.ch/pipermail/r-sig-finance/2012q1/009792.html)*

```{r dcc-var, eval=FALSE}
.VARs = c(TRUE, FALSE)
.rb = c(TRUE, FALSE)


```

### Hi-Lo

#### VAR=TRUE

#### VAR=FALSE

### Hi-Lo-Cl

#### VAR=TRUE

#### VAR=FALSE

### Cl

#### VAR=TRUE

#### VAR=FALSE

## GO-GARCH

```{r go-garch1, eval=FALSE}

.dist.models <- c('mvnorm', 'manig', 'magh')

## attributes of univariate stage 1
attributes(attributes(fit)$mfit$ufit)

## attributes of univariate stage 2
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit)
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[2]])$fit)
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[3]])$fit)

## AIC
-2*as.numeric(logLik(fit))+2*(length(fit$coefficients)+1)

-2 * as.numeric(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit$LLH) + 2*(length(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit$coef) + 1)
```

### Hi-Lo

#### VAR=TRUE

#### VAR=FALSE

### Hi-Lo-Cl

#### VAR=TRUE

#### VAR=FALSE

### Cl

#### VAR=TRUE

#### VAR=FALSE

## Copula-GARCH

### Hi-Lo

#### VAR=TRUE

#### VAR=FALSE

### Hi-Lo-Cl

#### VAR=TRUE

#### VAR=FALSE

### Cl

#### VAR=TRUE

#### VAR=FALSE

## CCC

*Multivariate DCC-GARCH Model* introduce the DCC and CCC models. In all tests for marginal goodness of fit the DCC-GARCH with skew Student's t-distributed errors outperformed the DCC-GARCH with Gaussian and Student's t-distributed errors. Comparing the DCC-GARCH model with the CCC-GARCH model using the Kupiec test showed that the DCC-GARCH model gave a better fit to the data. Here I skip the `cccgarch` package.

## BEKK

[[问答] 向各位朋友求助关于MGARCH-BEKK模型的问题！万分感谢！](http://bbs.pinggu.org/forum.php?mod=viewthread&tid=2263348) discuss about the BEKK model.

```
if (!((method == "Nelder-Mead") || (method == "BFGS") || 
        (method == "CG") || (method == "L-BFGS-B") || (method == 
        "SANN"))) {
        stop("'", method, "' method is not available")
    }
```

## mGJR (Bivariate GJR (bivariate asymmetric GARCH model))

`mGJR(eps1, eps2, order = c(1, 1, 1), params = NULL, fixed = NULL, method = "BFGS")`

```
if (!((method == "Nelder-Mead") || (method == "BFGS") || 
        (method == "CG") || (method == "L-BFGS-B") || (method == 
        "SANN"))) {
        stop("'", method, "' method is not available")
    }
```

The `mGJR()` function in `mgarchBEKK` use diversified optim function.



# Model Comparison

# Conclusion


```{r option, echo = FALSE}
## Set options back to original options
options(warn = 0)
```

# Appendix

## Documenting File Creation 

It's useful to record some information about how your file was created.

- File creation date: 2018-09-04
- File latest updated date: `r today('Asia/Tokyo')`
- `r R.version.string`
- R version (short form): `r getRversion()`
- [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
- File version: 1.0.1
- Author Profile: [®γσ, Eng Lian Hu](https://beta.rstudioconnect.com/content/3091/ryo-eng.html)
- GitHub: [Source Code](https://github.com/englianhu/binary.com-interview-question)
- Additional session information:

```{r info, echo=FALSE, warning=FALSE, results='asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))
suppressMessages(require('knitr', quietly = TRUE))
suppressMessages(require('kableExtra', quietly = TRUE))

sys1 <- devtools::session_info()$platform %>% 
  unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL

sys1 %<>% rbind(., data.frame(
  Category = 'Current time', 
  session_info = paste(as.character(lubridate::now('Asia/Tokyo')), 'JST'))) %>% 
  dplyr::filter(Category != 'os')

sys2 <- data.frame(Sys.info()) %>% mutate(Category = rownames(.)) %>% .[2:1]
names(sys2)[2] <- c('Sys.info')
rownames(sys2) <- NULL

cbind(sys1, sys2) %>% 
  kable(caption = 'Additional session information:') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))

rm(sys1, sys2)
```

## Reference

01. [Betting Strategy and Model Validation - Part II](https://englianhu.github.io/2017/10/Betting_Strategy_and_Model_Validation_-_Part_02/)
02. [**binary.com Job Application - Quantitative Analyst** *sample question*](https://github.com/englianhu/binary.com-interview-question)
03. [GARCH模型中的`ARIMA(p,d,q)`参数最优化](http://rpubs.com/englianhu/binary-Q1FiGJRGARCH)
04. [The `rmgarch` Models - Background and Properties](https://raw.githubusercontent.com/englianhu/binary.com-interview-question/master/reference/The%20rmgarch%20Models%20-%20Background%20and%20Properties.pdf)
05. [Financial Econometrics Practical - Univariate Volatility Modelling](https://raw.githubusercontent.com/englianhu/binary.com-interview-question/master/reference/Financial%20Econometrics%20Practical%20-%20Univariate%20Volatility%20Modelling.pdf)
06. [The GARCH-DCC Model and 2-Stage DCC(MVT) Estimation](http://www.unstarched.net/2013/01/03/the-garch-dcc-model-and-2-stage-dccmvt-estimation/)
07. [Multivariate Volatility Forecasting, Part 2 – Equicorrelation](https://eranraviv.com/multivariate-volatility-forecasting-2/)
29. [The Kelly Criterion - Implementation, Simulation and Backtest](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/The%20Kelly%20Criterion%20-%20Implementation%2C%20Simulation%20and%20Backtest.pdf)
30. [The Kelly Criterion and Bet Comparison in Spread Betting](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/The%20Kelly%20Criterion%20and%20Bet%20Comparisons%20in%20Spread%20Betting.pdf)
31. [The Kelly Criterion for Spread Bets](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/The%20Kelly%20Criterion%20for%20Spread%20Bets.pdf)
32. [The Market for English Premier League (EPL) Odds](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/The%20market%20for%20English%20Premier%20League%20(EPL)%20Odds.pdf)
33. [Valuation of Soccer Spread Bets](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Valuation%20of%20Soccer%20Spread%20Bets.pdf)
28. [Stochastic Modelling and Optimization Methods in Investments](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Stochastic%20Modeling%20and%20Optimization%20Methods%20in%20Investments.pdf)
15. [How Does the Fortune's Formula-Kelly Capital Growth Model Perform](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/How%20does%20the%20Fortune's%20Formula-Kelly%20Capital%20Growth%20Model%20Perform.pdf)
16. [Information Theory and Gambling or Economics](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Information%20Theory%20and%20Gambling%20or%20Economics.pdf)
17. [Investment Portfolio Optimization with GARCH Models](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Investment%20Portfolio%20Optimization%20with%20GARCH%20Models.pdf)
18. [Kelly Criterion Revisited - Optimal Bets](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Kelly%20Criterion%20Revisited%20-%20Optimal%20Bets.pdf)
21. [Medium Term Simulations of the Full Kelly and Fractional](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Medium%20Term%20Simulations%20of%20The%20Full%20Kelly%20and%20Fractional.pdf)
23. [Money Management (V1)](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Money%20Management%20(V1).pdf)
24. [Money Management (V2)](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Money%20Management%20(V2).pdf)
25. [Optimal Betting under Parameter Uncertainty - Improving the Kelly Criterion](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Optimal%20Betting%20under%20Parameter%20Uncertainty%20-%20Improving%20the%20Kelly%20Criterion.pdf)
13. [Enhancing Trading Strategies with Order Book Signals](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Enhancing%20Trading%20Strategies%20with%20Order%20Book%20Signals.pdf)
10. [Creating Optimal Portfolios of Stocks with Time-Varying Risk](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Creating%20Optimal%20Portfolios%20of%20Stocks%20with%20Time-Varying%20Risk.pdf)
11. [Dynamic Portfolio Optimization using Generalized Dynamic Conditoinal Heteroskedastic Factor Models](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Dynamic%20Portfolio%20Optimization%20using%20Generalized%20Dynamic%20Conditional%20Heteroskedastic%20Factor%20Models.pdf)
12. [Comparison of BEKK GARCH and DCC GARCH Models - An Empirical Study](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Comparison%20of%20BEKK%20GARCH%20and%20DCC%20GARCH%20Models%20-%20An%20Empirical%20Study.pdf)
13. [Do We Really Need Both BEKK and DCC - A Tale of Two Multivariate GARCH Models](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Do%20We%20Really%20Need%20Both%20BEKK%20and%20DCC%20-%20A%20Tale%20of%20Two%20Multivariate%20GARCH%20Models.pdf)
14. [Forecasting Conditional Correlation for Exchange Rates using Multivariate GARCH Models with Historical Value-at-Risk Application](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Forecasting%20Conditional%20Correlation%20for%20Exchange%20Rates%20using%20Multivariate%20GARCH%20Models%20with%20Historical%20Value-at-Risk%20Application.pdf)
15. [Volatility Spillover and Time-Varying Conditional Correlation between the European and US Stock Markets](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Volatility%20Spillover%20and%20Time-Varying%20Conditional%20Correl%3Bation%20between%20the%20European%20and%20US%20Stock%20Markets.pdf)
16. [Applying MGARCH Models in Finance](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Applying%20MGARCH%20Models%20in%20Finance.pdf)
17. [Comparison of Multivariate GARCH Models with Application to Zero-Coupon Bond Volatility](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Comparison%20of%20Multivariate%20GARCH%20Models%20with%20Application%20to%20Zero-Coupon%20Bond%20Volatility.pdf)
18. [Forecasting the Daily Dynamic Hedge Ratios by GARCH Models - Evidence from the Agricultural Futures Markets](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Forecasting%20the%20Daily%20Dynamic%20Hedge%20Ratios%20by%20GARCH%20Models%20-%20Evidence%20from%20the%20Agricultural%20Futures%20Markets.pdf)
19. [Currency Hedging Strategies Using Dynamic Multivariate GARCH](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Currency%20Hedging%20Strategies%20Using%20Dynamic%20Multivariate%20GARCH.pdf)
20. [Multivariate DCC-GARCH Model](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Multivariate%20DCC-GARCH%20Model.pdf)
21. [Introduction to the `rugarch` Package](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Introduction%20to%20the%20rugarch%20Package.pdf)
22. [How Good Are Your VaR Estimates?](http://www.unstarched.net/2012/12/26/how-good-are-your-var-estimates/)

---

**Powered by - Copyright® Intellectual Property Rights of <img src='www/oda-army2.jpg' width='24'> [Scibrokes®](http://www.scibrokes.com)個人の経営企業**
