---
title: "<img src='www/binary-logo-resize.jpg' width='240'>"
subtitle: "[binary.com](https://github.com/englianhu/binary.com-interview-question) Interview Question I - Comparison of Univariate GARCH Models"
author: "[®γσ, Lian Hu](https://englianhu.github.io/) <img src='www/ENG.jpg' width='24'> <img src='www/RYO.jpg' width='24'>®"
date: "`r lubridate::today('Asia/Tokyo')`"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE}
suppressPackageStartupMessages(library('BBmisc'))
#'@ suppressPackageStartupMessages(library('rmsfuns'))

pkgs <- c('knitr', 'kableExtra', 'tint', 'devtools', 'lubridate', 'data.table', 'quantmod', 'tidyquant', 'plyr', 'stringr', 'magrittr', 'dplyr', 'tidyverse', 'rlist', 'memoise', 'htmltools', 'highcharter', 'formattable', 'DT', 'rugarch', 'rmgarch', 'forecast')

suppressAll(lib(pkgs))
#'@ load_pkg(pkgs)

funs <- c('uv_fx.R', 'opt_arma.R', 'filterFX.R', 'filter_spec.R', 'task_progress.R', 'read_umodels.R')
l_ply(funs, function(x) source(paste0('./function/', x)))

options(warn = -1)
rm(pkgs)
```

# Introduction

There are quite some papers study on the GARCH models.

- **EGARCH, GKR-GARCH, TGARCH, AVGARCH, NGARCH, IGARCH and APARCH Models for Pathogens at Marine Recreational Sites**
- **Predictive Accuracy of GARCH, GJR and EGARCH Models Select Exchange Rates Application**

From previous papers, I tried to apply couple models for FOREX price forecasting and eventually got to know *Fractional Intergrated GJR-GARCH* is the best fit model as we can refer to **GARCH模型中的ARMA(p,d,q)参数最优化**^[Kindly refer to paper in [Reference]]. Due to I simulate whole dataset to get the result in menmtioned paper is time consuming, I tried to apply `dccroll()` to know the mse by resampling but not only based on single `AIC`^[Only the `solver=solnp` stable but the other solvers not stable, the fluctuation of AIC value is quite high.]. I parse my `mv_fx()` function^[Due to some errors] and tested the **Binary-Q1 - Multivariate GARCH Models** and some additive parameters might probably need to be adjusted in the arguments of the function. [Arma Part Overfitting in Arma Garch Model fitting via fGarch Package](https://stackoverflow.com/questions/36312065/arma-part-overfitting-in-arma-garch-model-fitting-via-fgarch-package) is a similar study for models comparison in GARCH.

I try to use 3 methods to compare the GARCH models.

- The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`: refit couple times in order to make sure the stability of the prediction model.
- Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`: refit once only with moving to know the prediction accuracy of the Markov model.
- Similar with Markov model above, but just seperates to `ugarchfit()` and `ugarchforecast()` and save every single observation. It will be easy to find the origin of error and rerun that particular data prediction.

Besides using the `ugarchroll()`, all models in this paper are Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`. **AMATH546 - ECON589 HW3** also teach the use of `ugarchroll()`.

```{r dcc, eval=FALSE}
## --- eval=FALSE, not run but display chunk ---
mv_fx <- function(...) {
  ...
  mod = dccroll(dccSpec, data = mbase, solver = .solver, 
                    forecast.length = 50, cluster = cl)
  cat('step 1/1 dccroll done!\n')
  ...
}

cl = makePSOCKcluster(ncol(mbase))

## Workable
test_roll <- dccroll(dccspec(
			multispec(c(ugarchspec(), ugarchspec(), ugarchspec(), 
			            ugarchspec(), ugarchspec(), ugarchspec(), 
			            ugarchspec())), distribution = 'mvt'), 
			data = mbase, cluster = cl)

## Not workable
test_roll2 <- dccroll(dccspec(
			multispec(c(
			  uspec1 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec2 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec3 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec4 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec5 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec6 = ugarchspec(variance.model = list(model = 'gjrGARCH')), 
				uspec7 = ugarchspec(variance.model = list(model = 'gjrGARCH'))
				))), data = mbase, cluster = cl)
#Error in checkForRemoteErrors(val) : 
#  one node produced an error: infinite or missing values in 'x'

## Workable
test_roll3 <- dccroll(dccspec(
			multispec(c(
			  uspec1 = ugarchspec(
			    variance.model = list(model = 'eGARCH'), 
			    distribution.model = 'snorm'), 
				uspec2 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm'), 
				uspec3 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm'), 
				uspec4 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm'), 
				uspec5 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm'), 
				uspec6 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm'), 
				uspec7 = ugarchspec(
				  variance.model = list(model = 'eGARCH'), 
				  distribution.model = 'snorm')
				)), distribution = 'mvt'), data = mbase, cluster = cl)

## Not workable
test_roll4 <- dccroll(dccspec(
			multispec(c(
			  uspec1 = ugarchspec(
			    variance.model = list(model = 'gjrGARCH'), 
			    distribution.model = 'snorm'), 
			  uspec2 = ugarchspec(
			    variance.model = list(model = 'gjrGARCH'), 
			    distribution.model = 'snorm'), 
				uspec3 = ugarchspec(
				  variance.model = list(model = 'gjrGARCH'), 
				  distribution.model = 'snorm'), 
				uspec4 = ugarchspec(
				  variance.model = list(model = 'gjrGARCH'), 
				  distribution.model = 'snorm'), 
				uspec5 = ugarchspec(
				  variance.model = list(model = 'gjrGARCH'), 
				  distribution.model = 'snorm'), 
				uspec6 = ugarchspec(
				  variance.model = list(model = 'gjrGARCH'), 
				  distribution.model = 'snorm'), 
				uspec7 = ugarchspec(
				  variance.model = list(model = 'gjrGARCH'), 
				  distribution.model = 'snorm')
				)), distribution = 'mvt'), data = mbase, cluster = cl)
#Error in checkForRemoteErrors(val) : 
#  one node produced an error: infinite or missing values in 'x'
```

**Binary-Q1**^[Kindly refer to paper in [Reference]] compares all possible GARCH models in `rugarch` package while the result is in ROI (Return on Investment), due to the paper **Binary-Q1 - Tick-Data-HiLo For Daily Trading <span style='color:red'>(Blooper)</span>** found that the betting strategy is not workable in real-life. Therefore I try to compare again the GARCH models as well as suite for multivariate GARCH models.

Due to the multivartiate models will not coped with every univariate models. Here I tried to compare the accuracy of forecasting by univariate GARCH models and later will compare with the multivariate models.

# Data

## Read Data

Similar with **GARCH模型中的ARMA(p,d,q)参数最优化**, I use the dataset from **Binary-Q1 (Extention)**^[Kindly refer to paper in [Reference]] to ease the study.

```{r read-data, warning=FALSE}
cr_code <- c('AUDUSD=X', 'EURUSD=X', 'GBPUSD=X', 'CHF=X', 'CAD=X', 
             'CNY=X', 'JPY=X')

#'@ names(cr_code) <- c('AUDUSD', 'EURUSD', 'GBPUSD', 'USDCHF', 'USDCAD', 
#'@                     'USDCNY', 'USDJPY')

names(cr_code) <- c('USDAUD', 'USDEUR', 'USDGBP', 'USDCHF', 'USDCAD', 'USDCNY', 'USDJPY')

## Read presaved Yahoo data.
mbase <- sapply(names(cr_code), function(x) readRDS(paste0('./data/', x, '.rds')) %>% na.omit)

price_type <- c('Op', 'Hi', 'Lo', 'Cl')

gmds <- c('sGARCH', 'fGARCH.GARCH', 'fGARCH.TGARCH', 'fGARCH.AVGARCH', 'fGARCH.NGARCH', 'fGARCH.NAGARCH', 'fGARCH.APARCH', 'fGARCH.GJRGARCH', 'fGARCH.ALLGARCH', 'eGARCH', 'gjrGARCH', 'apARCH', 'iGARCH', 'csGARCH')

timeID <- llply(mbase, function(x) as.character(index(x))) %>% 
  unlist %>% unique %>% as.Date %>% sort
timeID <- c(timeID, xts::last(timeID) + days(1)) #the last date + 1 in order to predict the next day of last date to make whole dataset completed.
timeID0 <- ymd('2013-01-01')
timeID <- timeID[timeID >= timeID0]

.cl = FALSE
```

# Testing Prediction Result

All my previous papers applied Markov theory which is $p(x_{n}|x_{n-1}...x_{1})$, here I try to test if the model provides same result. Here I iteration 100 times.

```{r em, eval=FALSE}
## ================ eval=FALSE ====================
## sample data.
x <- mbase[['USDJPY']] %>% Cl

armaOrder = opt_arma(x)
spec = ugarchspec(
    variance.model = list(
        model = 'sGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')

fit <- ugarchfit(spec, x, solver = 'hybrid')

## Execute 1 times.
fc1 = ugarchforecast(fit, n.ahead = 1)

## Execute 100 times to know if the coffecient value is applied ML method.
fc2 = replicate(100, ugarchforecast(fit, n.ahead = 1))

## retrieve the series and sigma values.
fc1 <- cbind(attributes(fc1)$`forecast`$seriesFor, attributes(fc1)$`forecast`$sigmaFor)

fc2 <- llply(fc2, function(x) cbind(attributes(x)$`forecast`$seriesFor, attributes(x)$`forecast`$sigmaFor)) %>% do.call('rbind', .)
fc2 %<>% unique

#> rbind(fc1, fc2)
#    2017-08-30 2017-08-30
#T+1   110.4566  0.6523954
#T+1   110.4566  0.6523954

#> fc1 == fc2
#    2017-08-30 2017-08-30
#T+1       TRUE       TRUE

rm(x)
```

From above test, we know that the prediction price is exactly same upon testing 100 times.

# GARCH Models

## sGARCH

### Method 1 : Resampling

Below is the backtest simulation. The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'` which only apply Monte Carlo method to resampling the model.

```{r msesGARCH}
if (!file.exists('data/fx/mse.sGARCH.rds')) {
  mse.sGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'sGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.sGARCH)[2] <- 'MSE'
  mse.sGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.sGARCH, 'data/fx/mse.sGARCH.rds')
  
} else {
  mse.sGARCH <- readRDS('data/fx/mse.sGARCH.rds')
}

mse.sGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate sGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.1.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

By refer to below article, I use `ugarchroll()` which is a wrapper for `ugarchfit()` and `ugarchforecast()` which will made the thing use :

- [estimation difference between ugarchroll and ugarchfit](http://r.789695.n4.nabble.com/estimation-difference-between-ugarchroll-and-ugarchfit-td4631122.html)
- [Window size in ugarchroll of rugarch package?](http://r.789695.n4.nabble.com/Window-size-in-ugarchroll-of-rugarch-package-td4669366.html)

There has a concern to use it which is once there has an error during the course of simulation will cause whole data gone.^[`tryCatch()` might useful for `llply()` or else we can use `for()` to skip `NULL` or error result. Normally I will add `cat()` upon completion of one prediction to know the progress of whole simulation.] All my previous preditive result based on the Markov Chain theory^[Markov Chain theory explain the statiscal predicton only can predict the next stage based on current stage. For example in soccer In-Play : 1-0 or 0-1 can be predicted during 0-0, the fit for 0-0 will not be usable anymore once there has scored. Similar concept with scoring intensity in **Dixon & Robinson 1997**, the `armaOrder` and `arfima` parameters optimised the preditive accuracy at every single stage.] with statistical modelling and prediction model and saved every single predictive result.

Below is the simulation . `n.start = ns` is the start point of simulation which is `ymd('2013-01-01')`, `forecast.length = nrow(x) - ns` is the length of forecast equal to the length from the n.start until the end of the dataset, `refit.every = 1` means re-estimate the fit value once only where `refit.window = 'moving'` where today's dataset only can predict 1 trading day in advance.

```{r msesGARCH2}
## --- eval=FALSE ---- Due to errors.
if (!file.exists('data/fx/mse.sGARCH2.rds')) {
  mse.sGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'sGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.sGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.sGARCH2, 'data/fx/mse.sGARCH2.rds')
  
} else {
  mse.sGARCH2 <- readRDS('data/fx/mse.sGARCH2.rds')
}

if (!is.null(mse.sGARCH2)) {
  mse.sGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate sGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.1.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Due to I am not statisfy and doubted onto the `AIC` result based on model comparison by using basic model above. Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q` to proof if my previous study^[gjrGARCH model generated highest ROI.] in **Binary.com Interview Q1** is correct.

**Binary.com Interview Q1 - Tick-Data-HiLo For Daily Trading <span style='color:red'>(Blooper)</span>** directly use the mentioned gjrGARCH model but add another criteria which is the timing of daily High-Low price based on highest `bid` and lowest `ask` price within a day.

```{r msesGARCH3, eval=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
sGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      sGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'sGARCH', currency = cr_code[i], 
                   price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(sGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(sGARCH[[i]])[3]))
      
      saveRDS(sGARCH[[i]], paste0(
        'data/fx/', names(sGARCH[[i]])[3], '/sGARCH.', 
        unique(sGARCH[[i]]$Date), '.rds'))
    
      cat(paste0(
        'data/fx/', names(sGARCH[[i]])[3], '/sGARCH.', 
        unique(sGARCH[[i]]$Date), '.rds saved!\n'))
    }
    }; rm(i)
  }
```

## fGARCH

### GARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-GARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.GARCH.rds')) {
  mse.fGARCH.GARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'GARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.GARCH)[2] <- 'MSE'
  mse.fGARCH.GARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.GARCH, 'data/fx/mse.fGARCH.GARCH.rds')
  
} else {
  mse.fGARCH.GARCH <- readRDS('data/fx/mse.fGARCH.GARCH.rds')
}

mse.fGARCH.GARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2], na.rm = TRUE))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-GARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.1.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-GARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.GARCH2.rds')) {
  mse.fGARCH.GARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'GARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.GARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.GARCH2, 'data/fx/mse.fGARCH.GARCH2.rds')
  
} else {
  mse.fGARCH.GARCH2 <- readRDS('data/fx/mse.fGARCH.GARCH2.rds')
}

if (!is.null(mse.fGARCH.GARCH2)) {
  mse.fGARCH.GARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-GARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.1.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-GARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.GARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.GARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'GARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.GARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.GARCH[[i]])[3]))
      
      saveRDS(fGARCH.GARCH[[i]], paste0(
        'data/fx/', names(fGARCH.GARCH[[i]])[3], '/fGARCH.GARCH.', 
        unique(fGARCH.GARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.GARCH[[i]])[3], '/fGARCH.GARCH.', 
        unique(fGARCH.GARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### TGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-TGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.TGARCH.rds')) {
  mse.fGARCH.TGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'TGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.TGARCH)[2] <- 'MSE'
  mse.fGARCH.TGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.TGARCH, 'data/fx/mse.fGARCH.TGARCH.rds')
  
} else {
  mse.fGARCH.TGARCH <- readRDS('data/fx/mse.fGARCH.TGARCH.rds')
}

mse.fGARCH.TGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-TGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.2.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-TGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.TGARCH2.rds')) {
  mse.fGARCH.TGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'TGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.TGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.TGARCH2, 'data/fx/mse.fGARCH.TGARCH2.rds')
  
} else {
  mse.fGARCH.TGARCH2 <- readRDS('data/fx/mse.fGARCH.TGARCH2.rds')
}

if (!is.null(mse.fGARCH.TGARCH2)) {
  mse.fGARCH.TGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-TGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.2.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-TGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.TGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.TGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'TGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                       Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
     if (!dir.exists(paste0('data/fx/', names(fGARCH.TGARCH[[i]])[3]))) 
       dir.create(paste0('data/fx/', names(fGARCH.TGARCH[[i]])[3]))
     
     saveRDS(fGARCH.TGARCH[[i]], paste0(
       'data/fx/', names(fGARCH.TGARCH[[i]])[3], '/fGARCH.TGARCH.', 
       unique(fGARCH.TGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.TGARCH[[i]])[3], '/fGARCH.TGARCH.', 
        unique(fGARCH.TGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### AVGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-AVGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.AVGARCH.rds')) {
  mse.fGARCH.AVGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'AVGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.AVGARCH)[2] <- 'MSE'
  mse.fGARCH.AVGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.AVGARCH, 'data/fx/mse.fGARCH.AVGARCH.rds')
  
} else {
  mse.fGARCH.AVGARCH <- readRDS('data/fx/mse.fGARCH.AVGARCH.rds')
}

mse.fGARCH.AVGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-AVGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.3.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-AVGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.AVGARCH2.rds')) {
  mse.fGARCH.AVGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'AVGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.AVGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.AVGARCH2, 'data/fx/mse.fGARCH.AVGARCH2.rds')
  
} else {
  mse.fGARCH.AVGARCH2 <- readRDS('data/fx/mse.fGARCH.AVGARCH2.rds')
}

if (!is.null(mse.fGARCH.AVGARCH2)) {
  mse.fGARCH.AVGARCH2 %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-AVGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.3.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-AVGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.AVGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
     dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
     smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
     
      fGARCH.AVGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'AVGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                       Type = paste0(names(df$latestPrice), '.', y), 
                       df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
     })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.AVGARCH[[i]])[3]))) 
       dir.create(paste0('data/fx/', names(fGARCH.AVGARCH[[i]])[3]))
     
     saveRDS(fGARCH.AVGARCH[[i]], paste0(
       'data/fx/', names(fGARCH.AVGARCH[[i]])[3], '/fGARCH.AVGARCH.', 
       unique(fGARCH.AVGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
       'data/fx/', names(fGARCH.AVGARCH[[i]])[3], '/fGARCH.AVGARCH.', 
       unique(fGARCH.AVGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### NGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-NGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.NGARCH.rds')) {
  mse.fGARCH.NGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'NGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.NGARCH)[2] <- 'MSE'
  mse.fGARCH.NGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.NGARCH, 'data/fx/mse.fGARCH.NGARCH.rds')
  
} else {
  mse.fGARCH.NGARCH <- readRDS('data/fx/mse.fGARCH.NGARCH.rds')
}

mse.fGARCH.NGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-NGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.4.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-NGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.NGARCH2.rds')) {
  mse.fGARCH.NGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'NGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.NGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.NGARCH2, 'data/fx/mse.fGARCH.NGARCH2.rds')
  
} else {
  mse.fGARCH.NGARCH2 <- readRDS('data/fx/mse.fGARCH.NGARCH2.rds')
}

if (!is.null(mse.fGARCH.NGARCH2)) {
  mse.fGARCH.NGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-NGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.4.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-NGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.NGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.NGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'NGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.NGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.NGARCH[[i]])[3]))
      
      saveRDS(fGARCH.NGARCH[[i]], paste0(
        'data/fx/', names(fGARCH.NGARCH[[i]])[3], '/fGARCH.NGARCH.', 
        unique(fGARCH.NGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.NGARCH[[i]])[3], '/fGARCH.NGARCH.', 
        unique(fGARCH.NGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### NAGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-NAGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.NAGARCH.rds')) {
  mse.fGARCH.NAGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'NAGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.NAGARCH)[2] <- 'MSE'
  mse.fGARCH.NAGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.NAGARCH, 'data/fx/mse.fGARCH.NAGARCH.rds')
  
} else {
  mse.fGARCH.NAGARCH <- readRDS('data/fx/mse.fGARCH.NAGARCH.rds')
}

mse.fGARCH.NAGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-NAGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.5.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-NAGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.NAGARCH2.rds')) {
  mse.fGARCH.NAGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'NAGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.NAGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.NAGARCH2, 'data/fx/mse.fGARCH.NAGARCH2.rds')
  
} else {
  mse.fGARCH.NAGARCH2 <- readRDS('data/fx/mse.fGARCH.NAGARCH2.rds')
}

if (!is.null(mse.fGARCH.NAGARCH2)) {
  mse.fGARCH.NAGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-NAGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.5.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-NAGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.NAGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.NAGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'NAGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.NAGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.NAGARCH[[i]])[3]))
      
      saveRDS(fGARCH.NAGARCH[[i]], paste0(
        'data/fx/', names(fGARCH.NAGARCH[[i]])[3], '/fGARCH.NAGARCH.', 
        unique(fGARCH.NAGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.NAGARCH[[i]])[3], '/fGARCH.NAGARCH.', 
        unique(fGARCH.NAGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### APARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-APARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.APARCH.rds')) {
  mse.fGARCH.APARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'APARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.APARCH)[2] <- 'MSE'
  mse.fGARCH.APARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.APARCH, 'data/fx/mse.fGARCH.APARCH.rds')
  
} else {
  mse.fGARCH.APARCH <- readRDS('data/fx/mse.fGARCH.APARCH.rds')
}

mse.fGARCH.APARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-APARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.6.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-APARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.APARCH2.rds')) {
  mse.fGARCH.APARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'APARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.APARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.APARCH2, 'data/fx/mse.fGARCH.APARCH2.rds')
  
} else {
  mse.fGARCH.APARCH2 <- readRDS('data/fx/mse.fGARCH.APARCH2.rds')
}

if (!is.null(mse.fGARCH.APARCH2)) {
  mse.fGARCH.APARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-APARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.6.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-APARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.APARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.APARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'APARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.APARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.APARCH[[i]])[3]))
      
      saveRDS(fGARCH.APARCH[[i]], paste0(
        'data/fx/', names(fGARCH.APARCH[[i]])[3], '/fGARCH.APARCH.', 
        unique(fGARCH.APARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.APARCH[[i]])[3], '/fGARCH.APARCH.', 
        unique(fGARCH.APARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### GJRGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-GJRGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.GJRGARCH.rds')) {
  mse.fGARCH.GJRGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'GJRGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.GJRGARCH)[2] <- 'MSE'
  mse.fGARCH.GJRGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.GJRGARCH, 'data/fx/mse.fGARCH.GJRGARCH.rds')
  
} else {
  mse.fGARCH.GJRGARCH <- readRDS('data/fx/mse.fGARCH.GJRGARCH.rds')
}

mse.fGARCH.GJRGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-GJRGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.7.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-GJRGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.GJRGARCH2.rds')) {
  mse.fGARCH.GJRGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'GJRGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.GJRGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.GJRGARCH2, 'data/fx/mse.fGARCH.GJRGARCH2.rds')
  
} else {
  mse.fGARCH.GJRGARCH2 <- readRDS('data/fx/mse.fGARCH.GJRGARCH2.rds')
}

if (!is.null(mse.fGARCH.GJRGARCH2)) {
  mse.fGARCH.GJRGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-GJRGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.7.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-GJRGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.GJRGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.GJRGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'GJRGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.GJRGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.GJRGARCH[[i]])[3]))
      
      saveRDS(fGARCH.GJRGARCH[[i]], paste0(
        'data/fx/', names(fGARCH.GJRGARCH[[i]])[3], '/fGARCH.GJRGARCH.', 
        unique(fGARCH.GJRGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.GJRGARCH[[i]])[3], '/fGARCH.GJRGARCH.', 
        unique(fGARCH.GJRGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

### ALLGARCH

#### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msefGARCH-ALLGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.ALLGARCH.rds')) {
  mse.fGARCH.ALLGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'ALLGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    
    if (!is.null(roll)) {
      res <- attributes(roll)$forecast$density %>% 
      tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.fGARCH.ALLGARCH)[2] <- 'MSE'
  mse.fGARCH.ALLGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.ALLGARCH, 'data/fx/mse.fGARCH.ALLGARCH.rds')
  
} else {
  mse.fGARCH.ALLGARCH <- readRDS('data/fx/mse.fGARCH.ALLGARCH.rds')
}

mse.fGARCH.ALLGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate fGARCH-ALLGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.8.1A : MSE of basket currencies.*

#### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msefGARCH-ALLGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.fGARCH.ALLGARCH2.rds')) {
  mse.fGARCH.ALLGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'fGARCH', garchOrder = c(1, 1), 
        submodel = 'ALLGARCH', external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    
    if (!is.null(roll)) {
      res <- attributes(roll)$forecast$density %>% 
      tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.fGARCH.ALLGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.fGARCH.ALLGARCH2, 'data/fx/mse.fGARCH.ALLGARCH2.rds')
  
} else {
  mse.fGARCH.ALLGARCH2 <- readRDS('data/fx/mse.fGARCH.ALLGARCH2.rds')
}

if (!is.null(mse.fGARCH.ALLGARCH2)) {
  mse.fGARCH.ALLGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate fGARCH-ALLGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.2.8.1B : MSE of basket currencies.*

#### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msefGARCH-ALLGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
fGARCH.ALLGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      fGARCH.ALLGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'fGARCH', .submodel = 'ALLGARCH', 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(fGARCH.ALLGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(fGARCH.ALLGARCH[[i]])[3]))
      
      saveRDS(fGARCH.ALLGARCH[[i]], paste0(
        'data/fx/', names(fGARCH.ALLGARCH[[i]])[3], '/fGARCH.ALLGARCH.', 
        unique(fGARCH.ALLGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(fGARCH.ALLGARCH[[i]])[3], '/fGARCH.ALLGARCH.', 
        unique(fGARCH.ALLGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

## eGARCH

### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r mseeGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.eGARCH.rds')) {
  mse.eGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'eGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.eGARCH)[2] <- 'MSE'
  mse.eGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.eGARCH, 'data/fx/mse.eGARCH.rds')
  
} else {
  mse.eGARCH <- readRDS('data/fx/mse.eGARCH.rds')
}

mse.eGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate eGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.3.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r mseeGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.eGARCH2.rds')) {
  mse.eGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'eGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.eGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.eGARCH2, 'data/fx/mse.eGARCH2.rds')
  
} else {
  mse.eGARCH2 <- readRDS('data/fx/mse.eGARCH2.rds')
}

if (!is.null(mse.eGARCH2)) {
  mse.eGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate eGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.3.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r mseeGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
eGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      eGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'eGARCH', .submodel = NULL, 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(eGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(eGARCH[[i]])[3]))
      
      saveRDS(eGARCH[[i]], paste0(
        'data/fx/', names(eGARCH[[i]])[3], '/eGARCH.', 
        unique(eGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(eGARCH[[i]])[3], '/eGARCH.', 
        unique(eGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

## gjrGARCH

### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msegjrGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.gjrGARCH.rds')) {
  mse.gjrGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'gjrGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.gjrGARCH)[2] <- 'MSE'
  mse.gjrGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.gjrGARCH, 'data/fx/mse.gjrGARCH.rds')
  
} else {
  mse.gjrGARCH <- readRDS('data/fx/mse.gjrGARCH.rds')
}

mse.gjrGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate gjrGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.4.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msegjrGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.gjrGARCH2.rds')) {
  mse.gjrGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'gjrGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.gjrGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.gjrGARCH2, 'data/fx/mse.gjrGARCH2.rds')
  
} else {
  mse.gjrGARCH2 <- readRDS('data/fx/mse.gjrGARCH2.rds')
}

if (!is.null(mse.gjrGARCH2)) {
  mse.gjrGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate gjrGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.4.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

Here I do not execute this model but directly read the previous dataset due to it is the model `pred2` in **GARCH模型中的ARMA(p,d,q)参数最优化**.

```{r msegjrGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
gjrGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      gjrGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'gjrGARCH', .submodel = NULL, 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(gjrGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(gjrGARCH[[i]])[3]))
      
      saveRDS(gjrGARCH[[i]], paste0(
        'data/fx/', names(gjrGARCH[[i]])[3], '/gjrGARCH.', 
        unique(gjrGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(gjrGARCH[[i]])[3], '/gjrGARCH.', 
        unique(gjrGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

## apARCH

### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r mseapARCH, echo=FALSE}
if (!file.exists('data/fx/mse.apARCH.rds')) {
  mse.apARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'apARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.apARCH)[2] <- 'MSE'
  mse.apARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.apARCH, 'data/fx/mse.apARCH.rds')
  
} else {
  mse.apARCH <- readRDS('data/fx/mse.apARCH.rds')
}

mse.apARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate apARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.5.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r mseapARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.apARCH2.rds')) {
  mse.apARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'apARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.apARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.apARCH2, 'data/fx/mse.apARCH2.rds')
  
} else {
  mse.apARCH2 <- readRDS('data/fx/mse.apARCH2.rds')
}

if (!is.null(mse.apARCH2)) {
  mse.apARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate apARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.5.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r mseapARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
apARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      apARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'apARCH', .submodel = NULL, 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(apARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(apARCH[[i]])[3]))
      
      saveRDS(apARCH[[i]], paste0(
        'data/fx/', names(apARCH[[i]])[3], '/apARCH.', 
        unique(apARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(apARCH[[i]])[3], '/apARCH.', 
        unique(apARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

## iGARCH

### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r mseiGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.iGARCH.rds')) {
  mse.iGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'iGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.iGARCH)[2] <- 'MSE'
  mse.iGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.iGARCH, 'data/fx/mse.iGARCH.rds')
  
} else {
  mse.iGARCH <- readRDS('data/fx/mse.iGARCH.rds')
}

mse.iGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate iGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.6.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r mseiGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.iGARCH2.rds')) {
  mse.iGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'iGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.iGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.iGARCH2, 'data/fx/mse.iGARCH2.rds')
  
} else {
  mse.iGARCH2 <- readRDS('data/fx/mse.iGARCH2.rds')
}

if (!is.null(mse.iGARCH2)) {
  mse.iGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate iGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.6.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r mseiGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
iGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      iGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'iGARCH', .submodel = NULL, 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(iGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(iGARCH[[i]])[3]))
      
      saveRDS(iGARCH[[i]], paste0(
        'data/fx/', names(iGARCH[[i]])[3], '/iGARCH.', 
        unique(iGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(iGARCH[[i]])[3], '/iGARCH.', 
        unique(iGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

## csGARCH

### Method 1 : Resampling

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`.

```{r msecsGARCH, echo=FALSE}
if (!file.exists('data/fx/mse.csGARCH.rds')) {
  mse.csGARCH <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'csGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    roll <- ugarchroll(spec, data = x, refit.window = 'recursive', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  #'@ names(mse.csGARCH)[2] <- 'MSE'
  mse.csGARCH %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.csGARCH, 'data/fx/mse.csGARCH.rds')
  
} else {
  mse.csGARCH <- readRDS('data/fx/mse.csGARCH.rds')
}

mse.csGARCH %>% 
  rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
  kable(caption = 'MSE for Univariate csGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.7.1A : MSE of basket currencies.*

### Method 2 : Markov Chain

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r msecsGARCH2, echo=FALSE}
if (!file.exists('data/fx/mse.csGARCH2.rds')) {
  mse.csGARCH2 <- ldply(mbase, function(x) {
    x <- Cl(x)
    if (.cl == TRUE) {
      .cl <- makePSOCKcluster(ncol(x))
    } else {
      .cl <- NULL
    }
    armaOrder = opt_arma(x)
    
    spec = ugarchspec(
      variance.model = list(
        model = 'csGARCH', garchOrder = c(1, 1), 
        submodel = NULL, external.regressors = NULL, 
        variance.targeting = FALSE), 
    mean.model = list(
        armaOrder = armaOrder[c(1, 3)], 
        include.mean = TRUE, archm = FALSE, 
        archpow = 1, arfima = TRUE, 
        external.regressors = NULL, 
        archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
    ns <- which(index(x) == timeID0)
    n <- nrow(x) - ns

    roll <- ugarchroll(spec, data = x, n.start = ns, forecast.length = n, 
                       refit.every = 1, refit.window = 'moving', 
                       cluster = .cl)
    res <- attributes(roll)$forecast$density
    
    if (!is.null(res)) {
      res %>% tbl_df %>% mutate(MSE = mean((Mu - Realized)^2)) %>% 
      .$MSE %>% unique
    } else {
      res <- NULL
    }
    return(res)
  }) %>% tbl_df
  mse.csGARCH2 %<>% ddply(.(.id), summarise, MSE = mean((Mu - Realized)^2))
  saveRDS(mse.csGARCH2, 'data/fx/mse.csGARCH2.rds')
  
} else {
  mse.csGARCH2 <- readRDS('data/fx/mse.csGARCH2.rds')
}

if (!is.null(mse.csGARCH2)) {
  mse.csGARCH2 %>% 
    rbind(., data.frame(.id = 'Mean', MSE = colMeans(.[2]))) %>% 
    kable(caption = 'MSE for Univariate csGARCH') %>% 
    kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
}
```

*Table 3.7.1B : MSE of basket currencies.*

### Method 3 : Markov Chain 2

Below I compared the Fractional Intergrated model which optimised the arfima `q` and also adjusted arma order `p` and `q`.

```{r msecsGARCH3, eval=FALSE, echo=FALSE}
## ------------- Simulate uv_fx() ----------------------
## uv_fx just made the model and some argument flexible.
csGARCH <- list()

for (dt in timeID) {
  
  for (i in seq(cr_code)) {
    
    smp <- mbase[[names(cr_code)[i]]]
    timeID2 <- c(index(smp), xts::last(index(smp)) + days(1))
    
    if (dt %in% timeID2) {
      dtr <- xts::last(index(smp[index(smp) < dt]), 1) #tail(..., 1)
      smp <- smp[paste0(dtr %m-% years(1), '/', dtr)]
      
      csGARCH[[i]] <- tryCatch({ldply(price_type, function(y) {
        df = uv_fx(smp, .model = 'csGARCH', .submodel = NULL, 
                   currency = cr_code[i], price = y, .cluster = .cl)
        df = data.frame(Date = index(df$latestPrice[1]), 
                        Type = paste0(names(df$latestPrice), '.', y), 
                        df$latestPrice, df$forecastPrice, t(df$AIC))
        names(df)[4] %<>% str_replace_all('1', 'T+1')
        df
      })}, error = function(e) NULL)
      
      if (!dir.exists(paste0('data/fx/', names(csGARCH[[i]])[3]))) 
        dir.create(paste0('data/fx/', names(csGARCH[[i]])[3]))
      
      saveRDS(csGARCH[[i]], paste0(
        'data/fx/', names(csGARCH[[i]])[3], '/csGARCH.', 
        unique(csGARCH[[i]]$Date), '.rds'))
      
      cat(paste0(
        'data/fx/', names(csGARCH[[i]])[3], '/csGARCH.', 
        unique(csGARCH[[i]]$Date), '.rds saved!\n'))
      }
    }; rm(i)
  }
```

# 1st Stage Model Comparison

## MSE, AIC and BIC

Due to some unknown reasons, the NGARCH and NAGARCH always bias to confuse the model selection. Here I try to look for some supportive methods.

### Calculate AIC for MSE

By refer to [How to Choose a Forecast for Your Time Series](http://kourentzes.com/forecasting/2016/06/17/how-to-choose-a-forecast-for-your-time-series), here I calculated the AIC of MSE to choose the best fitted model.

$$AIC = 2k - 2log(L)$$

where $k$ is the number of parameter, log is the logarithm and L is the likelihood function.

$$MSE = \sum_{i=1}^{n}(x_{i}-\mu_{i})^2$$

$$AIC = 2k+nlog(MSE)$$

### Using Bayes instead of AIC

Below picture shows the use of BIC for Markov model (as well as few parameters used in the model) while AIC for static model. For section [Resampling Method], we can refer to AIC while section [Markov Method] and section [Markov Method 2] we refer to BIC.

![](www/AIC-BIC.jpg)

### Calculate the MSE for AIC

In order to know the stability of AIC value, here I try to measure the mean squared error of AIC as well.

### Filter the Bias Data

As states, due to some unknown reasons, there has some data bias more than 100 times which is totally wrong. Some prediction price became AIC value and somemore the currency became `NULL` values after calculation.

Here I also filter and count the number of bias to pick the best fit model.

## Resampling Method

The default setting is `forecast.length = 500, refit.every = 25, refit.window = 'recursive'`. Below is the MSE summary for the models.

```{r pick-mse1A}
## remove all mse.*objects to save memory.
eval(parse(text = paste0('rm(\'', ls()[str_detect(ls(), 'mse.')],'\')')))

models <- llply(gmds, function(txt) {
    readRDS(paste0('data/fx/mse.', txt, '.rds')) %>% 
    data.frame(Cat = txt, .)
  })
names(models) <- gmds

models <- suppressAll(bind_rows(models)) %>% tbl_df %>% 
    mutate(Cat = factor(Cat), .id = factor(.id))

models %>% ddply(.(.id, Cat), summarise, MSE = mean(MSE, na.rm=TRUE)) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 25, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 26, 38, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 39, 49, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 50, 63, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 64, 76, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 77, 88, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

Due to some models unable produced a result, here I only filter and display the models with 7 currencies as below.

```{r pick-mse1B}
#'@ dplyr::count(models, Cat) %>% dplyr::filter(n == 7)
cats <- dplyr::count(models, Cat) %>% dplyr::filter(n == 7) %>% .[1] %>% unlist %>% factor

models %>% ddply(.(Cat), summarise, MSE = mean(MSE, na.rm=TRUE)) %>% 
    dplyr::filter(Cat %in% cats) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

Now I plot a table with rank where shows all possible models.

```{r m-mse, echo=FALSE}
m.mse <- models %>% spread(.id, MSE)

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "MSE Comparison"), 
           tags$h5(align = "center", class = "text-muted", 
                   "GARCH models")), 
  as.htmlwidget(m.mse %>% formattable(list(
    
    Cat = color_tile('white', 'darkgoldenrod'), 
    
    USDAUD = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDEUR = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
#    USDGBP = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCHF = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCAD = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCNY = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDJPY = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')) 
    ))))
```

## Markov Method

Set `n.start = ns`, `forecast.length = nrow(x) - ns`, `refit.every = 1`, `refit.window = 'moving'`.

```{r pick-mse2A, warning=FALSE, echo=FALSE}
models <- llply(gmds, function(txt) {
    dfm <- tryCatch(readRDS(paste0('data/fx/mse.', txt, '2.rds')), 
                    error = function(e) 
                      cat(paste0('data/fx/mse.', txt, '2.rds error!\n')))
    if(!is.null(dfm)) dfm %>% data.frame(Cat = txt, .)
  })
names(models) <- gmds

models <- suppressAll(bind_rows(models)) %>% tbl_df %>% 
    mutate(Cat = factor(Cat), .id = factor(.id))

models %>% 
  ddply(.(.id, Cat), summarise, MSE = mean(MSE, na.rm=TRUE)) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

Due to some models unable produced a result, here I only filter and display the models with 7 currencies as below.

```{r pick-mse2B, echo=FALSE}
#'@ dplyr::count(models, Cat) %>% dplyr::filter(n == 7)
cats <- dplyr::count(models, Cat) %>% 
  dplyr::filter(n == 7) %>% 
  .[1] %>% unlist %>% factor

models %>% 
  ddply(.(Cat), summarise, MSE = mean(MSE, na.rm=TRUE)) %>% 
    dplyr::filter(Cat %in% cats) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

Now I plot a table with rank where shows all possible models.

```{r m-mse2, echo=FALSE}
m.mse <- models %>% spread(.id, MSE)

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "MSE Comparison"), 
           tags$h5(align = "center", class = "text-muted", 
                   "GARCH models")), 
  as.htmlwidget(m.mse %>% formattable(list(
    
    Cat = color_tile('white', 'darkgoldenrod'), 
    
    USDAUD = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDEUR = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
 #   USDGBP = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCHF = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCAD = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDCNY = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')), 
    
    USDJPY = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 7), ' (rank: ', sprintf('%02d', rank(x)), ')')) 
    ))))
```

## Markov Method 2

Now, we look at the mse where I use `ugarchfit()` and `ugarchforecast`, actually it is same with above [Markov Method] but just seperate all prediction result as single file where we able to filter the error to find the most accurate model (as well as know he frequence of bias and precise among the models.).

### Data Progress

Below check the progress of the saved files. From below tables we can know how many day from date `r mbase$Date %>% range %>% .[1]` to date `r mbase$Date %>% range %>% .[2]` calculated. `x` indicate the number of days and `n` indicates the total number of trading days for that particular currency. One `x` contain OHLC 4 prices.

```{r check-progress}
## check how many data saved in progress.
l_ply(gmds, function(x) {
  x2 <- ifelse(x == 'gjrGARCH', 'pred2', x)
  task_progress(.pattern = paste0('^', x2, '.'), .loops = FALSE)
  })

## check latest date saved in progress.
#' @ l_ply(gmds, function(x) {
#' @   x2 <- ifelse(x == 'gjrGARCH', 'pred2', x)
#' @   task_progress(.date = TRUE, .pattern = paste0('^', x2, '.'), .loops = FALSE)
#' @   })
```

```{r read-models, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
## ------ EVAL = FALSE -------
## read all files which contain in mbase, missing files will prompt message.
if (!exists('fx')) {
  fx <- ldply(names(cr_code), function(x) {
    tmID <- index(mbase[[x]])
    tmID <- tmID[tmID >= ymd('2013-01-01') & 
                     tmID <= ymd('2017-08-30')]
    
    dfm <- ldply(gmds, function(y) {
      y2 <- ifelse(y == 'gjrGARCH', 'pred2', y)
      
      ldply(tmID, function(z) {
        txt <- paste0('data/fx/', x, '/', y2, '.', z, '.rds')
        tryCatch(readRDS(txt) %>% tbl_df, error = function(e) 
          cat(paste(txt, 'error, no such file.\n')))
            
        }) %>% data.frame(Model = factor(y), .) %>% tbl_df
      
    }) %>% data.frame(.id = factor(x), .) %>% tbl_df
    
    names(dfm)[5:6] <- c('Price', 'Price.T1')
    dfm
  }) %>% tbl_df
}
```

```{r read-models2, warning=FALSE, message=FALSE}
if (!exists('fx')) {
  fx <- read_umodels(cr_code, gmds, mbase, .print = FALSE)
}
```

```{r missing-files, echo=FALSE, eval=FALSE}
missing <- ldply(names(cr_code), function(x) {
    tmID <- index(mbase[[x]])
    tmID <- tmID[tmID >= ymd('2013-01-01') & 
                     tmID <= ymd('2017-08-30')]
    
    dfm <- ldply(gmds, function(y) {
      y2 <- ifelse(y == 'gjrGARCH', 'pred2', y)
      
      ldply(tmID, function(z) {
        txt <- paste0('data/fx/', x, '/', y2, '.', z, '.rds')
        tryCatch({
          fm <- readRDS(txt) %>% tbl_df
          fm <- NULL
          }, error = function(e) z)
          
        }) %>% data.frame(Model = factor(y), .) %>% tbl_df
      
    }) %>% data.frame(.id = factor(x), .) %>% tbl_df

    names(dfm)[3] <- 'Date'
    dfm
  }) %>% tbl_df

miss.timeID <- missing$Date %>% unique %>% sort
```

```{r tidy-data1, echo=FALSE, eval=FALSE}
## read all available files.
fx <- llply(gmds, function(x) {
    x2 <- ifelse(x == 'gjrGARCH', 'pred2', x)
    fx <- llply(names(cr_code), function(y) {
        fls <- list.files(paste0('data/fx/', y), 
                          pattern = paste0('^', x2, '.'))
        dfm <- ldply(fls, function(z) {
          txt <- paste0('data/fx/', y, '/', z)
            tryCatch(readRDS(txt), error = function(e) 
              cat(paste0(txt, ' error, no such file.\n')))
        }) %>% data.frame(Model = x, .) %>% tbl_df
        names(dfm)[4:5] <- c('Price', 'Price.T1')
        dfm
    })
    names(fx) <- names(cr_code)
    fx %<>% ldply %>% tbl_df
  })
names(fx) <- gmds

fx <- suppressAll(
  bind_rows(fx) %>% arrange(Date) %>% 
    mutate(.id = factor(.id), Model = factor(Model), 
           Price.T1 = lag(Price.T1, 56)) %>% 
    dplyr::filter(Date >= ymd('2013-01-01') & 
                  Date <= ymd('2017-08-30')))
```

### MSE and AIC

```{r aic1}
acc <- ddply(fx, .(.id, Model), summarise, 
             MSE = mean((Price.T1 - Price)^2), 
             n = length(Price), 
             AIC.MSE = (-2*MSE)/n+2*4/n, 
             MSE.AIC = mean((Akaike - mean(Akaike))^2), 
             Akaike = mean(Akaike), 
             Bayes = mean(Bayes), 
             Shibata = mean(Shibata), 
             Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))

acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

Above table is the raw prediction dataset without any filter. You can compare the best model based on more `n` and lowest MSE and AIC/BIC. However there has bias and also not yet filter some date without prediction result. For example :

- sGARCH does not has prediction result on AUDUSD on 2013-01-02.
- The open price of fGARCH.ALLGARCH on USDGBP on 2014-06-08 bias.
- The AIC and BIC value of eGARCH for currency USDJPY bias, hundred times than normal price.
- The data source close price gather from Yahoo for USDCNY is 2.856 but open, highest, lowest is normal. We cannot judge if the lowest price on that particular date is true or wrong, but need to filter as well.

```{r aic2}
acc <- ddply(fx, .(Model), summarise, 
             MSE = mean((Price.T1 - Price)^2), 
             n = length(Price), 
             AIC.MSE = (-2*MSE)/n+2*4/n, 
             MSE.AIC = mean((Akaike - mean(Akaike))^2), 
             Akaike = mean(Akaike), 
             Bayes = mean(Bayes), 
             Shibata = mean(Shibata), 
             Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))

acc %>% 
  kable(caption = 'Model Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

Above models compare all prediction result includes all bias and all possible result from calculation.

### Filtered MSE

Here I put this section as next topic as [Markov Method 2 : Filtered MSE] due to I need to filter OHLC, Close and HiLo three sub-sections.

# Markov Method 2 : Filtered MSE

## OHLC

### All Models

Due to some errors, the MSE values is not accurate. I can either filter AIC and BIC values or MSE values. Since the standard deviation based on price, even though the AIC value does not bias, but finally we take price figure but not the AIC figure.

- Normally we need to follow AIC and BIC figure, but some unknown errors cause the forecast price became AIC or BIC values etc
- Some unknown error made the AIC values bias 100 times than mean AIC value in their currency accordingly.

There is the solution for filter unknown error. Here I filtered all dataset which $\sigma^2_{i} >= 0.2$ and the AIC, BIC values just for reference in order to know there has .

```{r tidy-data2}
## filter all predictive error.
#'@ fx %>% mutate(diff = Price.T1 - Price, se = ifelse(abs(diff) > Price, 1, 0)) %>% .[,-c(8:10)] %>% dplyr::filter(se == 1) %>% data.frame

fx %<>% mutate(diff = abs(Price.T1/Price), 
               se = ifelse(diff <= 0.8 | diff >= 1.25, 1, 0))

## filter all predictive error where sd >= 20%.
notID <- fx %>% dplyr::filter(se == 1)
ntimeID <- notID %>% .$Date %>% unique %>% sort

## filter all date which contain OHLC of 7 currencies.
ntimeID2 <- fx %>% dplyr::count(Date) %>% 
    dplyr::filter(n == 392) %>% .$Date %>% sort #14 models x 7 currencies x OHLC 4 types = 392 observations per day.

acc <- fx %>% 
  dplyr::filter(!Date %in% ntimeID) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
      tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r ohlc-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary of MSE') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.1A : Table summary*

From above *table 6.1.1.1A*, we can compare the MSE of models which `n > 4000`. More number of observations, the testing of the prediction will be more accurate. For example, we try to look at the AIC and BIC values of the models, the `-6 < AIC < -8` and `-6 < BIC < -8` will be normal but `AIC < -10` and `BIC < -10` will be abnormal due to the MSE value is higher but AIC or BIC is lower.

```{r ohlc-price1B, echo=FALSE}
fx %>% dplyr::filter(!Date %in% ntimeID) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Table Summary of the Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.1B : Table summary*

Similar with *table 6.1.1.1A* but *table 6.1.1.1B* shows model breakdown without differentiate currency.

```{r ohlc-price1C, echo=FALSE}
fx %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Table Summary of Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.1.1.1C : Table summary number of errors.*

Table above compare the numnber of bias among the models. Less number of bias will be more accurate.

```{r ohlc-price1D, echo=FALSE}
notID %>% 
  kable(caption = 'Table Contains Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.1D : Table Contain Bias dataset.*

Above table shows the details of prediction result which bias. Based on above table, we can know every single wrong prediction result or wrong AIC/BIC. You can know which model predict which currency for which date is wrong or bias.

Now we try to filter the dataset which contain OHLC of 7 currecies.

```{r tidy-data3}
## Bias which contain OHLC of 7 currencies.
acc <- fx %>% dplyr::filter(Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r ohlc-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.2A : Table summary*

Due to different currency different standard deviation and mean value, therefore above *table 6.1.1.2A* compares the accuracy of the models which contain all currencies.

```{r ohlc-price2B, echo=FALSE}
## contain OHLC of 7 currencies.
fx %>% dplyr::filter(Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Table Summary Contain OHLC of 7 Currencies') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.2B : Table summary*

*table 6.1.1.2B* same with *table 6.1.1.2A* but not breakdown the currency. The number of `n` will be `7xn` of *table 6.1.1.2A* due to 7 currencies.

```{r ohlc-price2C, echo=FALSE}
fx %>% dplyr::filter(Date %in% ntimeID2 & se == 1) %>% 
  dplyr::count(Model) %>% 
  kable(caption = 'Table Summary of Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.1.1.2C : Table summary number of errors.*

Above table shows the number of bias.

```{r ohlc-price2D, echo=FALSE}
notID %>% dplyr::filter(Date %in% ntimeID2) %>% 
  kable(caption = 'Table Contains Bias Contain OHLC of 7 Currencies') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.2D : Table Contain Bias dataset.*

Table above list down all details which bias.

Lastly, we filter all bias data and look at the comparison of mse of OHLC of 7 currencies.

```{r tidy-data4}
## contain OHLC of 7 currencies without bias.
acc <- fx %>% dplyr::filter(Date %in% ntimeID2 & !Date %in% ntimeID) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r ohlc-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary Contain OHLC of 7 Currencies without Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.1.3A : Table summary*

```{r ohlc-price3B, echo=FALSE}
fx %>% dplyr::filter(Date %in% ntimeID2 & !Date %in% ntimeID) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Table Summary Contain OHLC of 7 Currencies without Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')

```

*6.1.1.3B : Table summary*

### Selected Models

Now I select 9 models which almost run all data from `r fx$Date %>% range %>% .[1]` to `r fx$Date %>% range %>% .[2]`. More observations will be able to know the best model. The models includes :

- sGARCH
- fGARCH.GARCH
- fGARCH.TGARCH
- fGARCH.NGARCH
- fGARCH.NAGARCH
- fGARCH.GJRGARCH
- gjrGARCH
- iGARCH
- csGARCH

```{r united-fx}
## filter gmds
gmds2 <- c('sGARCH', 'fGARCH.GARCH', 'fGARCH.TGARCH', 'fGARCH.NGARCH', 'fGARCH.NAGARCH', 'fGARCH.GJRGARCH', 'gjrGARCH', 'iGARCH', 'csGARCH')

## check completed dataset.
mdate <- fx %>% dplyr::filter(Model %in% gmds2) %>% 
  dplyr::count(Date, Model)

##filter 7 currency and OHLC data.
united.dateID <- mdate %>% dplyr::filter(n == 28) %>% 
  .$Date %>% unique %>% sort

united.fx <- fx %>% dplyr::filter(Model %in% gmds2 & Date %in% united.dateID) %>% 
  mutate(Model = factor(Model))

## filter all predictive error where sd >= 20%.
notID <- united.fx %>% 
  mutate(diff = abs(Price.T1/Price), 
         se = ifelse(diff <= 0.8 | diff >= 1.25, 1, 0)) %>% 
  dplyr::filter(se == 1)

ntimeID <- notID %>% .$Date %>% unique %>% sort

acc <- united.fx %>% dplyr::filter(!Date %in% ntimeID) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r ohlc-price4A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.1A : Table summary*

```{r ohlc-price4B, echo=FALSE}
united.fx %>% dplyr::filter(!Date %in% ntimeID) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.1B : Table summary*

```{r ohlc-price4C, echo=FALSE}
## number of prediction error.
dplyr::count(notID, Model) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.1.2.1C : Table summary*

```{r ohlc-price4D, echo=FALSE}
## prediction error details
notID %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.1D : Table summary*

Now I try to filter the dataset again. Below table summarise all dataset which excludes bias but contain OHLC of 7 currencies.

```{r united-fx2}
## filter all date which contain OHLC of 7 currencies.
ntimeID2 <- united.fx %>% dplyr::count(Date) %>% 
    dplyr::filter(n == 252) %>% .$Date %>% sort #9 models x 7 currencies x OHLC 4 types = 252 observations per day.

united.fx2 <- united.fx %>% dplyr::filter(Date %in% ntimeID2)

## filter all predictive error where sd >= 20%.
notID <- united.fx2 %>% 
  mutate(diff = abs(Price.T1/Price), 
         se = ifelse(diff <= 0.8 | diff >= 1.25, 1, 0)) %>% 
  dplyr::filter(se == 1)

acc <- united.fx2 %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r ohlc-price5A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.2A : Table summary*

```{r ohlc-price5B, echo=FALSE}
united.fx2 %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Summarised Table Excludes Bias and Contain OHLC of 7 Currencies') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.2B : Table summary*

```{r ohlc-price5C, echo=FALSE}
## prediction error details
notID %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.2C : Table summary*

Lastly, we filter all bias data and look at the comparison of mse of OHLC of 7 currencies.

```{r united-fx3}
## filter all date which excludes bias and also contain OHLC of 7 currencies.
united.fx3 <- united.fx2 %>% dplyr::filter(!Date %in% ntimeID)

acc <- united.fx3 %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

*6.1.2.3A : Table summary*

```{r ohlc-price6A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Group Table Summary Contain OHLC of 7 Currencies without Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.3B : Table summary*

```{r ohlc-price6B, echo=FALSE}
united.fx3 %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Table Summary Contain OHLC of 7 Currencies without Bias') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.1.2.3C : Table summary*

```{r plot-data, echo=FALSE, eval=FALSE}
## here we convert to xts format to plot data to compare it.
#'@ price <- united.fx[c('Date', 'Model', 'Type', 'Price', 'Price.T1')] %>% 
#'@     spread(Model, Price.T1) %>% 
#'@     split(.$Type) %>% 
#'@     llply(., function(x) xts(x[-c(1:2)], order.by = x$Date))

## here we keep as tibble format to plot data to compare it.
price <- united.fx2[c('Date', 'Model', 'Type', 'Price', 'Price.T1')] %>% 
    spread(Model, Price.T1) %>% 
    split(.$Type)
```

```{r plot-data2, echo=FALSE, eval=FALSE}
llply(price, function(x) {
  highchart() %>% 
    hc_xAxis(Time = x$Date) %>% 
    hc_add_series(name = names(x[3]), data = x$Price) %>% 
    hc_add_series(name = names(x[4]), data = x$sGARCH) %>% 
    hc_add_series(name = names(x[5]), data = x$fGARCH.GARCH) %>% 
    hc_add_series(name = names(x[6]), data = x$fGARCH.TGARCH) %>% 
    hc_add_series(name = names(x[7]), data = x$fGARCH.NGARCH) %>% 
    hc_add_series(name = names(x[8]), data = x$fGARCH.NAGARCH) %>% 
    hc_add_series(name = names(x[9]), data = x$fGARCH.GJRGARCH) %>% 
    hc_add_series(name = names(x[10]), data = x$gjrGARCH) %>% 
    hc_add_series(name = names(x[11]), data = x$iGARCH) %>% 
    hc_add_series(name = names(x[12]), data = x$csGARCH)
  })
```

```{r plot-data3, echo=FALSE, eval=FALSE}
## https://www.youtube.com/watch?v=go5Au01Jrvs
price %>% ggplot(aes(Date, Price)) + 
  geom_line(aes(group = ), alpha = 1/10)
```

## Open Price

### All Models

```{r open-price1}
## filtered bias closing price.
op <- fx %>% separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Op') %>% 
  dplyr::select(-Cur, -Type)

ntmID <- op %>% dplyr::filter(se == 1) %>% .$Date %>% unlist %>% sort

acc <- op %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r open-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Open Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.1.1 : Table summary*

Above table shows the `n` excludes the bias dataset. If the open price of particular currency on particular date is bias, then the highest, lowest and close preice will also not in count due to filter by date.

```{r open-price1B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
op %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Open Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.1.2 : Table summary*

Similar with *tabl 6.2.1.1* but without breakdown the currency.

```{r open-price1C, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Open Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.2.1.3 : Table summary*

```{r open-price1D, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.1.4 : Table summary*

### Selected Models

```{r open-price2}
## selected models' filtered closing price.
op <- united.fx2 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Op') %>% dplyr::select(-Cur, -Type)

acc <- op %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r open-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.1A : Table summary*

```{r open-price2B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
op %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.1B : Table summary*

```{r open-price2C, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.2.2.1C : Table summary*

```{r open-price2D, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.1D : Table summary*

```{r open-price3}
## selected models' filtered closing price.
op <- united.fx3 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Op') %>% dplyr::select(-Cur, -Type)

acc <- op %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r open-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.2A : Table summary*

```{r open-price3B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
op %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.2B : Table summary*

```{r open-price3C, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Open Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.2.2.2C : Table summary*

```{r open-price3D, echo=FALSE}
op %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.2.2.2D : Table summary*

## High Price

### All Models

```{r high-price1}
## filtered bias highest price.
hp <- fx %>% separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi') %>% 
  dplyr::select(-Cur, -Type)

ntmID <- hp %>% dplyr::filter(se == 1) %>% .$Date %>% unlist %>% sort

acc <- hp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r high-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'High Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.1.1 : Table summary*

```{r high-price1B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'High Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.1.2 : Table summary*

```{r high-price1C, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'High Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.3.1.3 : Table summary*

```{r high-price1D, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.1.4 : Table summary*

### Selected Models

```{r high-price2}
## selected models' filtered highest price.
hp <- united.fx2 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi') %>% dplyr::select(-Cur, -Type)

acc <- hp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r high-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.1A : Table summary*

```{r high-price2B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.1B : Table summary*

```{r high-price2C, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.3.2.1C : Table summary*

```{r high-price2D, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.1D : Table summary*

```{r high-price3}
## selected models' filtered highest price.
hp <- united.fx3 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi') %>% dplyr::select(-Cur, -Type)

acc <- hp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r high-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.2A : Table summary*

```{r high-price3B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.2B : Table summary*

```{r high-price3C, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'High Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.3.2.2C : Table summary*

```{r high-price3D, echo=FALSE}
hp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.3.2.2D : Table summary*

## Low Price

### All Models

```{r low-price1}
## filtered bias lowest price.
lp <- fx %>% separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Lo') %>% 
  dplyr::select(-Cur, -Type)

ntmID <- lp %>% dplyr::filter(se == 1) %>% .$Date %>% unlist %>% sort

acc <- lp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r low-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Low Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.1.1 : Table summary*

```{r low-price1B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
lp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Low Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.1.2 : Table summary*

```{r low-price1C, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Low Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.4.1.3 : Table summary*

```{r low-price1D, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.4 : Table summary*

### Selected Models

```{r low-price2}
## selected models' filtered lowest price.
lp <- united.fx2 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Lo') %>% dplyr::select(-Cur, -Type)

acc <- lp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r low-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.1A : Table summary*

```{r low-price2B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
lp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.1B : Table summary*

```{r low-price2C, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.4.2.1C : Table summary*

```{r low-price2D, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.2C : Table summary*

```{r low-price3}
## selected models' filtered lowest price.
lp <- united.fx3 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Lo') %>% dplyr::select(-Cur, -Type)

acc <- lp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r low-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.2A : Table summary*

```{r low-price3B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
lp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.2B : Table summary*

```{r low-price3C, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Low Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.4.2.2C : Table summary*

```{r low-price3D, echo=FALSE}
lp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.4.2.2D : Table summary*

## Close Price

### All Models

```{r close-price1}
## filtered bias closing price.
cp <- fx %>% separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Cl') %>% 
  dplyr::select(-Cur, -Type)

ntmID <- cp %>% dplyr::filter(se == 1) %>% .$Date %>% unlist %>% sort

acc <- cp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r close-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Close Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.1.1 : Table summary*

```{r close-price1B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
cp %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Close Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.1.2 : Table summary*

```{r close-price1C, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Close Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.5.1.3 : Table summary*

```{r close-price1D, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.1.4 : Table summary*

### Selected Models

```{r close-price2}
## selected models' filtered closing price.
cp <- united.fx2 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Cl') %>% dplyr::select(-Cur, -Type)

acc <- cp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r close-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.1A : Table summary*

```{r close-price2B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
cp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.1B : Table summary*

```{r close-price2C, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.5.2.1C : Table summary*

```{r close-price2D, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.1D : Table summary*

```{r close-price3}
## selected models' filtered closing price.
cp <- united.fx3 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Cl') %>% dplyr::select(-Cur, -Type)

acc <- cp %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r close-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.2A : Table summary*

```{r close-price3B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
cp %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.2B : Table summary*

```{r close-price3C, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Close Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.5.2.2C : Table summary*

```{r close-price3D, echo=FALSE}
cp %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.5.2.2D : Table summary*

## HiLo Price

Here I also measure the accuracy of mean value of highest and lowest. It may need to compare with the multivariate models.

### All Models

```{r hilo-price1}
## filtered bias hi-lo price.
hl <- fx %>% separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi'|Type == 'Lo') %>% 
  dplyr::select(-Cur, -Type)

ntmID <- hl %>% dplyr::filter(se == 1) %>% .$Date %>% unlist %>% sort

acc <- hl %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r hilo-price1A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Hi-Lo Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 14, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 15, 28, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 29, 42, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 43, 56, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 57, 70, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 71, 84, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 85, 98, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.1.1 : Table summary*

```{r hilo-price1B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hl %>% dplyr::filter(!Date %in% ntmID & Date %in% ntimeID2) %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Hi-Lo Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.1.2 : Table summary*

```{r hilo-price1C, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Hi-Lo Price Summary : All Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.6.1.3 : Table summary*

```{r hilo-price1D, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.1.4 : Table summary*

### Selected Models

```{r hilo-price2}
## selected models' filtered hi-lo price.
hl <- united.fx2 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi'|Type == 'Lo') %>% dplyr::select(-Cur, -Type)

acc <- hl %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r hilo-price2A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.1A : Table summary*

```{r hilo-price2B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hl %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.1B : Table summary*

```{r hilo-price2C, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.6.2.1C : Table summary*

```{r hilo-price2D, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.1D : Table summary*

```{r hilo-price3}
## selected models' filtered hi-lo price.
hl <- united.fx3 %>% 
  separate(Type, c('Cur', 'Type')) %>% 
  dplyr::filter(Type == 'Hi'|Type == 'Lo') %>% dplyr::select(-Cur, -Type)

acc <- hl %>% 
  ddply(.(.id, Model), summarise, 
        MSE = mean((Price.T1 - Price)^2), 
        n = length(Price), 
        AIC.MSE = (-2*MSE)/n+2*4/n, 
        MSE.AIC = mean((Akaike - mean(Akaike))^2),
        Akaike = mean(Akaike), 
        Bayes = mean(Bayes), 
        Shibata = mean(Shibata), 
        Hannan.Quinn = mean(Hannan.Quinn)) %>% 
  tbl_df %>% mutate(MSE = round(MSE, 7))
```

```{r hilo-price3A, echo=FALSE}
acc %>% arrange(.id) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  group_rows('USD/AUD', 1, 9, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CAD', 10, 18, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CHF', 19, 27, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/CNY', 28, 36, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/EUR', 37, 45, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/GBP', 46, 54, label_row_css = 'background-color: #003399; color: #fff;') %>%
  group_rows('USD/JPY', 55, 63, label_row_css = 'background-color: #003399; color: #fff;') %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.2A : Table summary*

```{r hilo-price3B, echo=FALSE}
## filter the dataset to know how many prediction sd < 0.1.
hl %>% 
    ddply(.(Model), summarise, 
      MSE = mean((Price.T1 - Price)^2), 
      n = length(Price), 
      AIC.MSE = (-2*MSE)/n+2*4/n, 
      MSE.AIC = mean((Akaike - mean(Akaike))^2),
      Akaike = mean(Akaike), 
      Bayes = mean(Bayes), 
      Shibata = mean(Shibata), 
      Hannan.Quinn = mean(Hannan.Quinn)) %>% 
    tbl_df %>% mutate(MSE = round(MSE, 7)) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.2B : Table summary*

```{r hilo-price3C, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% dplyr::count(Model) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*6.6.2.2C : Table summary*

```{r hilo-price3D, echo=FALSE}
hl %>% dplyr::filter(se == 1) %>% 
  kable(caption = 'Hi-Lo Price Summary : Selected Models') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*6.6.2.2D : Table summary*

# GARCH(1,1)?

I had optimised the `mean.model` but not yet optimise the `variance.model`, **Binary.com Interview Q1 - Tick-Data-HiLo For Daily Trading (Blooper)** has provides an example for GARCH(m,n) comparison while below are the papers studied on the optimal GARCH order.

- [Optimal lag order selection for a GARCH model](https://stats.stackexchange.com/questions/175400/optimal-lag-order-selection-for-a-garch-model?answertab=votes#tab-top)
- [Does anything NOT beat the GARCH(1,1)?](http://unstarched.net/2013/01/07/does-anything-not-beat-the-garch11/)
- [How to choose the order of a GARCH model?](https://stats.stackexchange.com/questions/154754/how-to-choose-the-order-of-a-garch-model?answertab=votes#tab-top)

Above article states that the task of jointly determining the ARMA-GARCH orders is difficult...

# Distribution Model

I set `snorm` as the default distribution from the comparison of ROI in **Binary-Q1**^[Kindly refer to paper in [Reference]]. [**rgarchdist** - Distribution:Rugarch Distribution Functions](https://www.rdocumentation.org/packages/rugarch/versons/1.4-0/topics/rgarchdist) list the available distribution function for `rugarch`.

**Does anything NOT beat the GARCH(1,1)?** had compared few GARCH models which are :

- GARCH
- GJR
- EGARCH
- APARCH
- component GARCH
- AVGARCH
- NGARCH
- NAGARCH

with four distributions, the Normal, Skew-Student (Fernandez and Steel version), Normal Inverse Gaussian (`NIG`) and Johnson’s SU (`JSU`). The conditional mean was based on an ARMA(2,1) model, while the GARCH order was set at (1,1) and (2,1), giving a total combination of 64 models. To create the rolling forecasts, the `ugarchroll()` was used...

The author concludes that the normality assumption does not realistically capture the observed market dynamics, and neither does the GARCH(1,1)-N model. There were few models which did not beat it in this application. In fact, higher order GARCH models were shown to provide significant out performance on a range of tail related measures, and distributions such as the `NIG` and `JSU` appeared to provide the most realistic representation of the observed dynamics.

The author proof that the matrix relationship^[Therefore I skip [2nd Stage Model Comparison], my previous paper use 2nd stage parameter adjustment but noticed that the matrix relationship will correct.] among the distribution and models in order to get the best fit model. However there are couple of thesises proof that the best fit model for forex, stocks market is difference.

Here I skipped the distribution section due to above model comparison in section [GARCH Models] has compare the models... **Binary.com Interview Q1** has compare the models as well.

- `norm` for normal distribution.
- `snorm` for skew-normal distribution.
- `std` for student-t distribution.
- `sstd` for skew-student distribution.
- `ged` for generalized error distribution.
- `sged` for skew-generalized error distribution.
- `nig` for normal inverse gaussian distribution.
- `ghyp` for generalized hyperbolic distribution.
- `jsu` for Johnson's SU distribution.

# Solver

The article **Does anything NOT beat the GARCH(1,1)?** using `hybrid` same with my previous paper **Binary.com Interview Q1** where my paper test and choose it since it is best fit for gjrGARCH model.

- nlminb
- solnp
- lbfgs
- gosolnp
- nloptr
- hybrid

# Review on Binary-Q1

**GARCH模型中的`ARMA(p,d,q)`参数最优化** compare the accuracy of the model and the paper **Binary.com Interview Q1 - Tick-Data-HiLo For Daily Trading <span style='color:red'>(Blooper)</span>** states the wrong of the staking model in **Binary.com Interview Q1** as I use the price as odds price without calculate the loss.^[VaR or other risk amount, the loss amount will be 1 for the exchange rate since $\frac{100yen}{1}=100yen$ while I use the closed price as settled price if the forecast settled price has no within the range of Hi-Lo price within a trading day. There will be a leverage and slot unit required for financial market while a risk amount will be required for financial betting.] However, here I try to review on paper **Binary.com Interview Q1** to compare the accuracy of prediction.

In order to validate the accuracy of prediction, here I added this section to compare among the models. I added a mean mse for Hi and Lo in order to know the long term accuracy between Hi-Lo since an order stand upon the accuracy of both Hi and Lo. **binary-Q1 Multivariate GARCH Models** will be another study for both punter and banker.

```{r mse1}
## read files
fls <- list.files('data', patter = '.snorm.hybrid.rds$')
mds <- llply(fls, function(txt) {
    tryCatch(readRDS(paste0('data/', txt)), 
             error = function(e) cat(paste0('data/', txt, ' error!\n')))
    })
names(mds) <- str_replace_all(fls, '.rds', '')

## measure mse.
mds <- llply(names(mds), function(x) {
  HiLo <- x %>% str_extract_all('Hi.Lo|Lo.Hi|Hi.Cl|Lo.Cl|Op.Hi|
                                 Op.Lo|Op.Cl') %>% unlist
  if (length(HiLo) > 0) {
    dfm <- mds[[x]]
    
    if (HiLo == 'Hi.Lo') {
      dfm %<>% mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
                     mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique
      
    } else if (HiLo == 'Lo.Hi') {
      dfm %<>% mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
                     mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Hi.Cl') {
      dfm %<>% mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
                     mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Lo.Cl') {
      dfm %<>% mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
                     mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Op.Hi') {
      dfm %<>% mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
                     mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Op.Lo') {
      dfm %<>% mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
                     mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique

    } else if (HiLo == 'Op.Cl') {
      dfm %<>% mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
                     mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else {
      stop('No such option.')
    }
    dfm %<>% .[, -c(1:26)] %>% unique
  }
  })
names(mds) <- str_replace_all(fls, '.rds', '')

mds %<>% ldply

mds %>%  mutate(mse.HiLo = (mse.Hi + mse.Lo)/2) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

Here I filtered the `sd < 20%` dataset as below.

```{r mse2}
## read files
fls <- list.files('data', patter = '.snorm.hybrid.rds$')
mds <- llply(fls, function(txt) {
    tryCatch(readRDS(paste0('data/', txt)), 
             error = function(e) cat(paste0('data/', txt, ' error!\n')))
    })
names(mds) <- str_replace_all(fls, '.rds', '')

## measure mse.
mds <- llply(names(mds), function(x) {
  HiLo <- x %>% str_extract_all('Hi.Lo|Lo.Hi|Hi.Cl|Lo.Cl|Op.Hi|
                                 Op.Lo|Op.Cl') %>% unlist
  if (length(HiLo) > 0) {
    dfm <- mds[[x]]
    
    if (HiLo == 'Hi.Lo') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.High), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.Low), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
               mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique
      
    } else if (HiLo == 'Lo.Hi') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.Low), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.High), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
               mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Hi.Cl') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.High), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.Close), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Lo.Cl') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.Low), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.Close), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Op.Hi') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.Open), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.High), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Op.Lo') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.Open), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.Low), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique

    } else if (HiLo == 'Op.Cl') {
      dfm %<>% mutate(diff1 = abs(Point.Forecast/USDJPY.Open), 
                      se1 = ifelse(diff1 <= 0.8 | diff1 >= 1.25, 1, 0), 
                      diff2 = abs(forClose/USDJPY.Close), 
                      se2 = ifelse(diff2 <= 0.8 | diff2 >= 1.25, 1, 0)
                      ) %>% 
        dplyr::filter(se1 != 1 & se2 != 1) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else {
      stop('No such option.')
    }
    dfm %<>% .[, -c(1:30)] %>% unique
  }
  })
names(mds) <- str_replace_all(fls, '.rds', '')

mds %<>% ldply

mds %>% mutate(mse.HiLo = (mse.Hi + mse.Lo)/2) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

Now I filtered the forecast price must be within highest and lowest price in order to made the order stand.

```{r mse3}
## read files
fls <- list.files('data', patter = '.snorm.hybrid.rds$')
mds <- llply(fls, function(txt) {
    tryCatch(readRDS(paste0('data/', txt)), 
             error = function(e) cat(paste0('data/', txt, ' error!\n')))
    })
names(mds) <- str_replace_all(fls, '.rds', '')

## measure mse.
mds <- llply(names(mds), function(x) {
  HiLo <- x %>% str_extract_all('Hi.Lo|Lo.Hi|Hi.Cl|Lo.Cl|Op.Hi|
                                 Op.Lo|Op.Cl') %>% unlist
  if (length(HiLo) > 0) {
    dfm <- mds[[x]]
    
    if (HiLo == 'Hi.Lo') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
               mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique
      
    } else if (HiLo == 'Lo.Hi') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
               mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Hi.Cl') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Hi = mean((Point.Forecast - USDJPY.High)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Lo.Cl') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Lo = mean((Point.Forecast - USDJPY.Low)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else if (HiLo == 'Op.Hi') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Hi = mean((forClose - USDJPY.High)^2)) %>% unique

    } else if (HiLo == 'Op.Lo') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Lo = mean((forClose - USDJPY.Low)^2)) %>% unique

    } else if (HiLo == 'Op.Cl') {
      dfm %<>% dplyr::filter(Point.Forecast <= USDJPY.High & 
                             Point.Forecast >= USDJPY.Low & 
                             forClose <= USDJPY.High & 
                             forClose >= USDJPY.Low) %>% 
        mutate(mse.Op = mean((Point.Forecast - USDJPY.Open)^2), 
               mse.Cl = mean((forClose - USDJPY.Close)^2)) %>% unique

    } else {
      stop('No such option.')
    }
    dfm %<>% .[, -c(1:26)] %>% unique
  }
  })
names(mds) <- str_replace_all(fls, '.rds', '')

mds %<>% ldply

mds %>% mutate(mse.HiLo = (mse.Hi + mse.Lo)/2) %>% 
  kable(caption = 'Summary') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

# Conclusion

## Conclusion Words

Due to some unknown reason, the NGARCH and NAGARCH (and other models, some currencies as well.)^[Kindly refer to section [MSE, AIC and BIC].] always bias, therefore the AIC/BIC value and the mse value opposite site to made we hard to judge if it is good to fit. Fortunately I try to filter the bias where $\sigma ≥ 20\%$ and count the number of occurance to pick the model. You can compare the average MSE, AIC, BIC values of all models but skip the bias model(s) which bias hundred times or almost x2 of average of the rest of models. You can also refer to the number of bias or even look into the details of the bias observation.

If we compare the model which most accurate for all currencies prediction, gjrGARCH still be the best model among all models however you can select other model for specific currency.

![](www/accuracy-precision.jpg)

## Future Works

Perhaps the other day will compare the matrix models fit with distribution and solver. The multivariate GARCH model is also on going. There will be perfect if I saved the VaR 1% and 5% since it will be required in order to test the efficiency of ROI with multivariate models.

We can use specific model for different currencies for multivariate models.


```{r option, echo=FALSE}
## Set options back to original options
options(warn = 0)
```

# Appendix

## Speech and Blooper

There are a lot of time I waste just for verify and rerun the coding. `ugarchroll` function always interrupted after running few hours. The simulation wrote by me always interrupt as well, there are 14 GARCH models while I running 6 models at the meantime. `ugarchroll` for `refit.windows = 'recrusive'` cost me few days time while  `refit.windows = 'moving'` cost me weeks time and all in 24 hours without any rest.

After get the MSE value and AIC value, I forced to debug the codes upon unexpected results especially bias. For example, the MSE value judge the best fit model but AIC and BIC judge as worst model. Here I also looking for some reference like AIC for MSE which applied AIC for compare the best MSE as introduced by a professor.

Below are the blooper (behind the scene) for **GARCH模型中的ARMA(p,d,q)参数最优化** where I use almost a week to review and filter couple times.

![](www/blooper-01.jpg)

This paper compares 14 models with 3 mthods but **GARCH模型中的ARMA(p,d,q)参数最优化** only compares 2 models.

## Documenting File Creation 

It's useful to record some information about how your file was created.

- File creation date: 2018-08-12
- File latest updated date: `r today('Asia/Tokyo')`
- `r R.version.string`
- R version (short form): `r getRversion()`
- [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
- File version: 1.0.1
- Author Profile: [®γσ, Eng Lian Hu](https://beta.rstudioconnect.com/content/3091/ryo-eng.html)
- GitHub: [Source Code](https://github.com/englianhu/binary.com-interview-question)
- Additional session information:

```{r info, echo=FALSE, warning = FALSE, results = 'asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))

sys1 <- devtools::session_info()$platform %>% unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL

sys1 %<>% rbind(., data.frame(Category = 'Current time', session_info = paste(as.character(now('Asia/Tokyo')), 'JST')))

sys2 <- data.frame(Sys.info()) %>% mutate(Category = rownames(.)) %>% .[2:1]
names(sys2)[2] <- c('Sys.info')
rownames(sys2) <- NULL

cbind(sys1, sys2) %>% 
  kable(caption = 'Additional session information:') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))

rm(sys1, sys2)
```

## Reference

01. [GARCH模型中的`ARMA(p,d,q)`参数最优化](http://rpubs.com/englianhu/binary-Q1FiGJRGARCH)
02. [Binary.com Interview Q1](http://rpubs.com/englianhu/binary-Q1) ([Old link](https://englianhu.github.io/2017/09/binary-forex-trading-Q1.html) or [Alternate link](http://rpubs.com/englianhu/binary-forex-trading-Q1))
03. [Binary.com Interview Q1 (Extention)](http://rpubs.com/englianhu/binary-Q1E) or ([Alternate link](http://rpubs.com/englianhu/316133))
04. [Binary.com Interview Q1 - Tick-Data-HiLo For Daily Trading <span style='color:red'>(Blooper)</span>](http://rpubs.com/englianhu/binary-Q1TD)
05. [41901 Probability and Statistics](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/41901%20Probability%20and%20Statistics.pdf)
06. [A Comparison of Volatility Models - Does Anything Beat a GARCH(1,1)](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/A%20Comparison%20of%20Volatility%20Models%20-%20Does%20Anything%20Beat%20a%20GARCH(1%2C1).pdf)
07. [A Winners Curse for Econometric Models - On the Joint Distribution of In-Sample Fit and Out-of-Sample Fit and Its Implications for Model Selection](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/A%20Winners%20Curse%20for%20Econometric%20Models%20-%20On%20the%20Joint%20Distribution%20of%20In-Sample%20Fit%20and%20Out-of-Sample%20Fit%20and%20its%20Implications%20for%20Model%20Selection.pdf)
08. [AMATH546 - ECON589 HW3](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/AMATH546%20-%20ECON589%20HW3.pdf)
09. [ARMA(1,1)-GARCH(1,1) Estimation and Forecast using rugarch 1.2-2](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/ARMA(1%2C1)-GARCH(1%2C1)%20Estimation%20and%20Forecast%20using%20rugarch%201.2-2.pdf)
10. [EGARCH, GKR-GARCH, TGARCH, AVGARCH, NGARCH, IGARCH and APARCH Models for Pathogens at Marine Recreational Sites](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/EGARCH%2C%20GJR-GARCH%2C%20TGARCH%2C%20AVGARCH%2C%20NGARCH%2C%20%20IGARCH%20and%20APARCH%20Models%20for%20Pathogens%20at%20Marine%20Recreational%20Sites.pdf)
11. [GARCH Models in Value at Risk Estimation Empirical Evidence from Montenegrin Stock Exchange](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/GARCH%20Models%20in%20Value%20at%20Risk%20Estimation%20Empirical%20Evidence%20from%20the%20Montenegrin%20Stock%20Exchange.pdf)
12. [Predicting Stock Price Returns using Garch Model](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Predicting%20Stock%20Prices%20Returns%20using%20Garch%20Model.pdf)
13. [Predictive Accuracy of GARCH, GJR and EGARCH Models Select Exchange Rates Application](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Predictive%20Accuracy%20of%20GARCH%2C%20GJR%20and%20EGARCH%20Models%20Select%20Exchange%20Rates%20Application.pdf)
14. [Which GARCH Model is Best for Value-at-Risk](https://github.com/englianhu/binary.com-interview-question/blob/master/reference/Which%20GARCH%20Model%20is%20Best%20for%20Value-at-Risk.pdf)
15. [Optimal lag order selection for a GARCH model](https://stats.stackexchange.com/questions/175400/optimal-lag-order-selection-for-a-garch-model?answertab=votes#tab-top)
16. [Does anything NOT beat the GARCH(1,1)?](http://unstarched.net/2013/01/07/does-anything-not-beat-the-garch11)
17. [How to choose the order of a GARCH model?](https://stats.stackexchange.com/questions/154754/how-to-choose-the-order-of-a-garch-model?answertab=votes#tab-top)

---

**Powered by - Copyright® Intellectual Property Rights of <img src='www/oda-army2.jpg' width='24'> [Scibrokes®](http://www.scibrokes.com)個人の経営企業**
